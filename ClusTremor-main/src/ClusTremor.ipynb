{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855ba09c",
   "metadata": {},
   "source": [
    "# Set up your environment\n",
    "\n",
    "Use the mlgeo enviroment from class\n",
    "Install any missing packages\n",
    "TODO: create new env file that includes all of these packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d453252-815f-4065-8315-7a65b23d3b65",
   "metadata": {},
   "source": [
    "## initial installation\n",
    "### start with environment from class\n",
    "\n",
    "> %pip install h5py\n",
    "%pip install keras\n",
    "%pip install --upgrade tensorflow\n",
    "%pip install sklearn\n",
    "%pip install seaborn\n",
    "%pip install pydot\n",
    "%pip install pydot graphviz     # for plotting model\n",
    "%pip install librosa\n",
    "%pip show tensorflow\n",
    "\n",
    "#TODO write requirements.txt to include all of these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os, re, glob\n",
    "import math\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dropout, Reshape \n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization, ZeroPadding1D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam, schedules\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfd94ad-da04-4977-b403-be9d1cd7b6c3",
   "metadata": {},
   "source": [
    "### Optional - LFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a81f52",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 14px;\">\n",
    "Input.npy is a Git LFS (Large File Storage) pointer to a large data file.\n",
    "\n",
    "To download the file:\n",
    "\n",
    "1. Install Git LFS (if you haven't already) AND you're on a system where you have sudo access\n",
    "    ```python\n",
    "    sudo apt-get install git-lfs\n",
    "    ```\n",
    "2. Initialize Git LFS in your repo (if you haven't already)\n",
    "    ```python\n",
    "    git lfs install\n",
    "    ```\n",
    "3. Track .npy Files with Git LFS\n",
    "    ```python\n",
    "    git lfs track \"*.npy\"\n",
    "    ```\n",
    "\n",
    "After you have cloned the repo, download the data file:\n",
    "\n",
    "`    git lfs pull`\n",
    "\n",
    "\n",
    "Note that the file is about 230MB. Running this locally will take a while. Using memory-map will save some time:\n",
    "\n",
    "> The mmap_mode parameter in NumPy's np.load function allows you to memory-map a file, which means that the file is not fully loaded into memory. Instead, it is mapped to a portion of the virtual memory, allowing you to access parts of the file on demand. This is particularly useful for working with large files that do not fit into memory.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef79091",
   "metadata": {},
   "source": [
    "# Load data and split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e562e-458d-4f4d-98ad-afc1778647c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data from https://geofon.gfz-potsdam.de/doi/network/9F/2021\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"beginning to load file...\")\n",
    "\n",
    "# memory-map the file, which is read-only by default\n",
    "data_file = np.load(\"Input.npy\", mmap_mode='r') # Seismic data from station NUPH should be cited as: doi:10.14470/4S7576570845\n",
    "\n",
    "print(\"file loaded\")\n",
    "\n",
    "print(\"split data into training and testing sets\")\n",
    "train, test= train_test_split (data_file, test_size=0.2, train_size=0.8, random_state=46, shuffle=True)\n",
    "\n",
    "print ('size-data_file='+str (data_file.shape), 'size-train='+str (train.shape),'size-test='+str (test.shape) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e4850-cc71-4419-a0f0-641ba43f765a",
   "metadata": {},
   "source": [
    "# Autoencoder architecture construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b71a-84ff-417c-8261-54b91ce52507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "sd=46\n",
    "seed(sd)\n",
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(sd)\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dense, Input, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "# import tensorflow as tf\n",
    "import tensorflow.keras.backend as K \n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=sd)\n",
    "\n",
    "inp = Input(shape=(96, 128, 1))  \n",
    "e = Conv2D(8, (7, 5),strides=[2,2], activation='elu', kernel_initializer=initializer, padding='same')(inp)\n",
    "e = Conv2D(16, (5, 3),strides=[2,2], activation='elu', kernel_initializer=initializer, padding='same')(e)\n",
    "e = Conv2D(32, (5, 3),strides=[2,2], activation='elu', kernel_initializer=initializer, padding='same')(e)\n",
    "e = Conv2D(64, (5, 3),strides=[2,2], activation='elu' , kernel_initializer=initializer, padding='same')(e)\n",
    "\n",
    "# use tf.keras.backend.int_shape to get the shape of a tensor\n",
    "shape_before_flattening = tf.keras.backend.int_shape(e)\n",
    "encoded1 = Flatten()(e)\n",
    "\n",
    "encoded2= Dense (24, activation='elu')(encoded1)\n",
    "fc= Dense (3072, activation='elu')(encoded2)\n",
    "\n",
    "d = Reshape(shape_before_flattening[1:])(fc)\n",
    "    \n",
    "d = Conv2DTranspose(32, (5, 3), strides=[2,2], activation='elu', kernel_initializer=initializer, padding='same')(d)\n",
    "d = Conv2DTranspose(16, (5, 3), strides=[2,2], activation='elu', kernel_initializer=initializer, padding='same')(d)\n",
    "d = Conv2DTranspose(8, (5, 3),strides=[2,2] , activation='elu', kernel_initializer=initializer, padding='same')(d)\n",
    "decoded = Conv2DTranspose(1, (7, 5),strides=[2,2] , activation='linear', kernel_initializer=initializer, padding='same')(d)\n",
    "\n",
    "autoencoder = Model(inputs=inp, outputs=decoded, name='autoencoder')\n",
    "encoder = Model(inputs=inp, outputs=encoded2, name='encoder')\n",
    "\n",
    "# use tf.keras.utils.plot_model to visualize the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image, display\n",
    "\n",
    "autoencoder.summary()\n",
    "\n",
    "# Specify the full path for the output file\n",
    "output_path = os.path.join(os.getcwd(), 'autoencoder.png')\n",
    "\n",
    "#TODO: make this display more interesting\n",
    "try:\n",
    "    plot_model(autoencoder, to_file=output_path, show_shapes=True, show_layer_names=True)\n",
    "    display(Image(filename=output_path, width=800, height=600))\n",
    "except Exception as e:\n",
    "    print(f\"Error creating or displaying model plot: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc2c677",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Specify the directory where the logs will be stored\n",
    "log_dir = \"logs/autoencoder/\" \n",
    "\n",
    "# Create the TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Fit your autoencoder with TensorBoard callback\n",
    "autoencoder.fit(\n",
    "    train, train, \n",
    "    batch_size=32,\n",
    "    epochs=50, \n",
    "    validation_data=(test, test), \n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/autoencoder/ \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fc658d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "# Specify the directory where the logs will be stored\n",
    "log_dir = \"logs/autoencoder/\"\n",
    "\n",
    "# Create the TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Compile your autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Start the profiler\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "print(\"profiler started\")\n",
    "\n",
    "# Fit your autoencoder with TensorBoard callback\n",
    "autoencoder.fit(\n",
    "    train, train, \n",
    "    batch_size=32,\n",
    "    epochs=10, \n",
    "    validation_data=(test, test), \n",
    "    callbacks=[tensorboard_callback]\n",
    ")\n",
    "\n",
    "# Export the trace\n",
    "tf.summary.trace_export(name=\"encoder_trace\", step=0, profiler_outdir=log_dir)\n",
    "print(\"profiler stopped\")\n",
    "\n",
    "# Load and launch TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/autoencoder/ \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ebb90-94ed-4ffd-8627-3ca2b0deff1b",
   "metadata": {},
   "source": [
    "# Initial training phase: Pretraining the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe502b67-0ee0-4126-ae3b-7f9e7664592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise number to 500 during actual run\n",
    "# 50 is faster, so use it for setup\n",
    "NUM_OF_EPOCHS = 500\n",
    "\n",
    "lr_schedule = schedules.ExponentialDecay(\n",
    "    initial_learning_rate= 0.001,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.5)\n",
    "\n",
    "### Adapting the learning rate of the optimizer using an exponential decay schedule\n",
    "\n",
    "optimizer = Adam(learning_rate=lr_schedule)   \n",
    "\n",
    "# Define the callbacks\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "csv_logger = CSVLogger('pretrain_log.csv')\n",
    "# original lien:\n",
    "#es = EarlyStopping( monitor='val_loss', mode='min', verbose=1, patience=30), CSVLogger('pretrain_log.csv')\n",
    "\n",
    "autoencoder.compile(optimizer=optimizer, loss='mse')\n",
    "autoencoder.fit(train, train, batch_size=32, epochs=NUM_OF_EPOCHS ,validation_data=(test, test), callbacks=[es, csv_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512cbed-9eae-492a-b841-0b39131536a5",
   "metadata": {},
   "source": [
    "# Evaluate autoencoder reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936d9d0-7330-4320-82ff-4e89648ce8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pretrain_log.csv')\n",
    "fig= plt.figure(figsize=(7, 5))\n",
    "plt.plot(df['epoch'],df['loss'], color='b',label='Training Loss', linewidth=3.0)\n",
    "plt.plot(df['epoch'],df['val_loss'], color='darkorange',label='Validation Loss', linewidth=3.0)\n",
    "\n",
    "plt.ylabel('Loss', fontsize= 18)\n",
    "plt.xlabel('Epoch', fontsize= 18)\n",
    "plt.title('Reconstruction loss of the autoencoder', fontsize= 18)\n",
    "plt.yticks (fontsize= 18)\n",
    "plt.xticks (fontsize= 18)\n",
    "\n",
    "plt.legend(loc= 1, frameon= False, fontsize= 18)\n",
    "plt.tight_layout()\n",
    "plt.show ()\n",
    "fig.savefig ( 'ReconstructionLoss.png', dpi= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ec57e47-07ea-4e45-81e7-d30efd3bc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the model\n",
    "\n",
    "# original\n",
    "# autoencoder.save ('autoencoder-model')\n",
    "\n",
    "autoencoder.save('autoencoder-model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e508f0-1ad1-4309-a41f-5739b8f6fa7d",
   "metadata": {},
   "source": [
    "### Autoencoder input-output visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e01374-a800-49ce-9213-5e3dded6f220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded_imgs = autoencoder.predict(data_file)\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "s=300\n",
    "e=305\n",
    "n = e-s\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(s,e):\n",
    "    \n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i-s + 1)\n",
    "    librosa.display.specshow(data_file[i,:,:], alpha=None, cmap='hot', antialiased=True)\n",
    "    plt.colorbar ()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i-s + 1 + n)\n",
    "    librosa.display.specshow(decoded_imgs[i,:,:,0], alpha=None, cmap='hot', antialiased=True)\n",
    "    plt.colorbar ()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604a8d6-4a34-43c7-81e3-ef55d39ba8a9",
   "metadata": {},
   "source": [
    "## Kmeans clustering based on extracted features from the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64671bcb-0ff8-414c-aacf-fa7ce2e18424",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=1, random_state=46, n_init=20).fit(encoder.predict(data_file))\n",
    "y = kmeans.predict(encoder.predict(data_file))\n",
    "\n",
    "def plotter(S, y):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    \n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    plt.scatter(S[y == 0, 0], S[y == 0, 1],color='navy', alpha=.5, lw=lw, s=100)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "    f.savefig ('Tnse-km-n1', dpi= 100,bbox_inches = \"tight\")\n",
    "\n",
    "    return f, ax\n",
    "\n",
    "enc = encoder.predict(data_file)\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n",
    "plotter(redu, y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc9c74",
   "metadata": {},
   "source": [
    "TODO: this plot doesn't look like the paper's plot\n",
    "This will make the following images look different from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcc610-b758-430f-8159-505dcad5d000",
   "metadata": {},
   "source": [
    "# Determining optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a5528-9064-4cee-b5b9-7f246de16eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "cal = []\n",
    "K = range(2,16)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=20).fit(encoder.predict(data_file))\n",
    "    labelskm = kmeans.predict(encoder.predict(data_file))\n",
    "    cal.append(calinski_harabasz_score(encoder.predict(data_file), labelskm))\n",
    "fig= plt.figure(figsize=(7, 5))\n",
    "plt.plot(K, cal, 'bx-')\n",
    "plt.xlabel('Number of clusters',fontsize= 18)\n",
    "plt.ylabel('Calinski-Harabasz score',fontsize= 18)\n",
    "plt.title('Calinski-Harabasz Score Elbow for K-means Clustering',fontsize= 18)\n",
    "plt.yticks (fontsize= 18)\n",
    "plt.xticks (fontsize= 18)\n",
    "plt.axvline(x = 4, color = 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig ( 'Calinski score.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565b504-f0a8-4324-b24c-4a21aab6f345",
   "metadata": {},
   "source": [
    "# T-sne visualizations of seismic event clusters in feature domain after pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ec66b-cd4d-426f-9fd6-255078c97428",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4, random_state=46, n_init=20).fit(encoder.predict(data_file))\n",
    "y = kmeans.predict(encoder.predict(data_file))\n",
    "\n",
    "def plotter(S, y, target_names):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    # choose a color palette with seaborn.\n",
    "    colors = [ 'red', 'mediumblue','darkorange','turquoise','lime', 'turquoise', 'darkorange','lawngreen', 'red', 'saddlebrown']\n",
    "    \n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    for color, i, target_name in zip(colors, [3,0, 1,2], target_names):\n",
    "        plt.scatter(S[y == i, 0], S[y == i, 1], color=color, alpha=.5, lw=lw, s=100, label=target_name)\n",
    "    plt.legend(loc='lower left', shadow=False, scatterpoints=1, prop={'size': 26})\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "    f.savefig ('Tnse-km-n4', dpi= 100,bbox_inches = \"tight\")\n",
    "\n",
    "    return f, ax\n",
    "\n",
    "enc = encoder.predict(data_file)\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n",
    "target_names = ['cluster 1', 'cluster 2', 'cluster 3', 'cluster 4']\n",
    "plotter(redu, y, target_names) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc368d8-35b2-4ce4-bd45-66a0ac5c3661",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d69729d-d928-432e-b3df-a094b7d185af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "autoencoder = load_model(\"autoencoder-model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbee693-4cdc-49c7-a5d9-7e11517e2418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Assuming autoencoder and data_file are already defined\n",
    "layer_outputs = [layer.output for layer in autoencoder.layers[1:]]\n",
    "activation_model = tf.keras.models.Model(inputs=autoencoder.input, outputs=layer_outputs)\n",
    "\n",
    "# Get the outputs of all layers\n",
    "layer_output = activation_model.predict(data_file)\n",
    "\n",
    "# Display the outputs\n",
    "for i, output in enumerate(layer_output):\n",
    "    print(f\"Layer {i+1} output shape: {output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8a3f4cf-8b29-4ab4-bdaa-e32250578df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters=4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6d620-b779-4741-acf2-d6846c24949c",
   "metadata": {},
   "source": [
    "# Integrating clustering layer into autoencoder bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3549ee2-a05b-4c8e-8b3f-ef5de83470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "sd=46\n",
    "seed(sd)\n",
    "#import tensorflow\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(sd)\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=sd)\n",
    "\n",
    "#### clustering layers\n",
    "class ClusteringLayer(Layer):\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=2)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 2\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=tf.keras.backend.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer= initializer , name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "    \n",
    "    def call(self, inputs, **kwargs):\n",
    "        q = 1.0 / (1.0 + (tf.keras.backend.sum(tf.keras.backend.square(tf.keras.backend.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = tf.keras.backend.transpose(tf.keras.backend.transpose(q) / tf.keras.backend.sum(q, axis=1)) \n",
    "        return q\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 2\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "\n",
    "print('...Finetuning...')   \n",
    "\n",
    "clustering_layer = ClusteringLayer(n_clusters=n_clusters, name='clustering')(autoencoder.layers[6].output)\n",
    "model = Model(inputs=autoencoder.input, outputs=clustering_layer)\n",
    "model.compile(loss='kld', loss_weights=0.1, optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "\n",
    "plot_model(model, to_file='model.png', show_shapes=True)\n",
    "Image(filename='model.png')\n",
    "\n",
    "# ORIGINAL FROM REPO\n",
    "# clustering_layer = ClusteringLayer(n_clusters, name='clustering')(autoencoder.layers[6].output)\n",
    "# model = Model(inputs=autoencoder.layers[0].output, outputs=clustering_layer)\n",
    "# model.compile(loss='kld', loss_weights=0.1,  optimizer=SGD(learning_rate=0.01,  momentum=0.9))\n",
    "\n",
    "\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "# Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6d89e-b3ef-4667-924c-6d1fbb058479",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initializing the weights using Kmean and assigning them to the model\n",
    "print(\"Number of clusters in KMeans model: \", kmeans.n_clusters)\n",
    "print(\"Number of clusters in 'clustering': \", model.get_layer(name='clustering').n_clusters)\n",
    "\n",
    "print(\"n_clusters = \", n_clusters)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=46, n_init=20)\n",
    "y_pred = kmeans.fit_predict(layer_output[5])\n",
    "y_pred_last = np.copy(y_pred)\n",
    "model.get_layer(name='clustering').set_weights([kmeans.cluster_centers_])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dbf3a-6ee3-4e02-98d9-c8733db0497e",
   "metadata": {},
   "source": [
    "# Finetuning pre-trained model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69466dfc-7290-4226-9b6e-9309ffbeefd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## parameters for the finetuning\n",
    "\n",
    "batch_size=32 \n",
    "tol = 0.0001 # tolerance threshold to stop training\n",
    "loss = 0\n",
    "index = 0\n",
    "#maxiter = 50000 \n",
    "maxiter = 100\n",
    "update_interval = 200 \n",
    "index_array = np.arange(data_file.shape[0])\n",
    "y_pred_last = np.zeros(data_file.shape[0])\n",
    "index_array = np.arange(data_file.shape[0])\n",
    "\n",
    "\n",
    "# simultaneous optimization and clustering\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / np.sum(q, axis=0)\n",
    "    return (weight.T / np.sum(weight, axis=1)).T\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    print(f'ite in first loop: {ite}')\n",
    "    if ite % update_interval == 0:\n",
    "        print(f'starting inner loop')\n",
    "        q = model.predict(data_file, verbose=0)\n",
    "        p = target_distribution(q)  # update the auxiliary target distribution p       \n",
    "        y_pred = q.argmax(1) # evaluate the clustering performance\n",
    "\n",
    "        loss = np.round(loss, 5)\n",
    "        print(f'Iter {ite}: ; loss={loss}')\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "\n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print(f'delta_label {delta_label} < tol {tol}')\n",
    "            break\n",
    "        \n",
    "        IN = layer_output[5]\n",
    "    \n",
    "    start_idx = index * batch_size\n",
    "    end_idx = min((index + 1) * batch_size, data_file.shape[0])\n",
    "    idx = index_array[start_idx:end_idx]\n",
    "    \n",
    "    #idx = index_array[index * batch_size: min((index+1) * batch_size, data_file.shape[0])]\n",
    "    loss = model.train_on_batch(x=data_file[idx], y=p[idx])\n",
    "    #index = index + 1 if (index + 1) * batch_size <= data_file.shape[0] else 0\n",
    "    index = (index + 1) % (data_file.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e376ef-bcee-43d5-8c95-e7eb43046704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORIGINAL import tensorflow as tf\n",
    "\n",
    "# ORIGINAL get_all_layer_outputs = tf.keras.backend.function([autoencoder.layers[0].input],\n",
    "#                                   [l.output for l in autoencoder.layers[1:]])\n",
    "# ORIGINAL layer_output = get_all_layer_outputs([data_file]) # return the same thing\n",
    "\n",
    "# The error occurs because the function method has been moved or deprecated in TensorFlow 2.x.\n",
    "# Instead of using tf.keras.backend.function, you should use tf.keras.models.Model to extract\n",
    "# the outputs of specific layers.\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define a new model to get the output of each layer\n",
    "layer_outputs = [layer.output for layer in autoencoder.layers[1:]]\n",
    "get_all_layer_outputs = Model(inputs=autoencoder.input, outputs=layer_outputs)\n",
    "\n",
    "# Now, you can get the outputs for input 'data_file'\n",
    "layer_output = get_all_layer_outputs.predict(data_file)  # Use .predict() instead of calling the function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9705825-856b-4645-a5aa-414155ef00a8",
   "metadata": {},
   "source": [
    "# T-sne visualizations of seismic event clusters in feature domain after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5f876-8994-4086-9074-ae0780173492",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y_pred\n",
    "\n",
    "def plotter(S, y, target_names):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    # choose a color palette with seaborn.\n",
    "    colors = ['red', 'mediumblue','darkorange','turquoise', 'lawngreen', 'red', 'saddlebrown']\n",
    "    \n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    for color, i, target_name in zip(colors, [3,0, 1,2], target_names):\n",
    "        plt.scatter(S[y == i, 0], S[y == i, 1], color=color, alpha=0.5, lw=lw, s=100, label=target_name)\n",
    "    plt.legend(loc='lower left', shadow=False, scatterpoints=1, prop={'size': 26})\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "    f.savefig ('Tsne-km-n4-ft.png', dpi= 100,bbox_inches = \"tight\")\n",
    "    \n",
    "    return f, ax\n",
    "\n",
    "enc = layer_output[5]\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n",
    "target_names = [ 'Earthquakes (EQ)','Continuous tremors 1 (CT1)', 'Episodic tremors (ET)', 'Continuous tremors 2 (CT2)' ]\n",
    "plotter(redu, y, target_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a10236-cc2f-48df-8ac5-7482e19f9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the labels\n",
    "np.savetxt('km-n4-ft.txt', y, fmt='%i', delimiter=',')\n",
    "\n",
    "# Change the order of the cluster numbers (just for a nice representation)\n",
    "\n",
    "with open('km-n4-ft.txt', 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('3', 'data_file')\n",
    "filedata = filedata.replace('2', '3')\n",
    "filedata = filedata.replace('1', '2')\n",
    "filedata = filedata.replace('0', '1')\n",
    "filedata = filedata.replace('data_file', '0')\n",
    "\n",
    "# Re-write the output\n",
    "with open('km-n4-ft.txt', 'w') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb231f-9bae-4f09-8adf-906789cec64d",
   "metadata": {},
   "source": [
    "### Visualizing cluster changes across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1b419-d268-47f7-a850-037dc1bd6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "y= np.loadtxt ('km-n4-ft.txt')\n",
    "fig= plt.figure(figsize=(18, 4))\n",
    "ax = fig.add_subplot()\n",
    "x1=list(range(0,2390))\n",
    "colors = ['red', 'mediumblue','darkorange','turquoise']\n",
    "cmap_name = 'my_list'\n",
    "cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "ax.scatter (x1, y, c=y, cmap=cmap, s= 30, alpha=0.2)\n",
    "ax.set_yticks ([0, 1, 2,3])\n",
    "ax.set_yticklabels (['EQ','CT1', 'ET','CT2'], fontsize=18)\n",
    "plt.ylabel('Clusters', fontsize= 18)\n",
    "\n",
    "ax.set_xticks ([0,175,417,708,996,1117,1425,1782,2142,2390])\n",
    "ax.set_xticklabels (['12 March','19 March','30 March','15 April','27 April','2 May','15 May','30 May','14 June','24 June'], fontsize=16)\n",
    "ax.axvline (x=174, linewidth=4, color='black')\n",
    "ax.axvline (x=996, linewidth=4, color='black')\n",
    "ax.axvline (x=2127, linewidth=4, color='black')\n",
    "\n",
    "plt.xlim (0,2390)\n",
    "#plt.xlim (980,1020)\n",
    "plt.tight_layout()\n",
    "fig.savefig ( 'Temporal Cluster Changes.png', dpi= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff7eec-7915-4152-85ce-4aa2c978466f",
   "metadata": {},
   "source": [
    "# Cluster-wise autoencoder input-output visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a56f5-eea9-451d-a61d-3b6a480110f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "autoencoder = load_model(\"autoencoder-model.keras\")\n",
    "\n",
    "#get_all_layer_outputs = K.function([autoencoder.layers[0].input], [l.output for l in autoencoder.layers[1:]])\n",
    "\n",
    "# Define a function to get outputs from all layers\n",
    "@tf.function\n",
    "def get_all_layer_outputs(inputs):\n",
    "    outputs = [layer.output for layer in autoencoder.layers[1:]]\n",
    "    model = tf.keras.Model(inputs=autoencoder.input, outputs=outputs)\n",
    "    return model(inputs)\n",
    "\n",
    "layer_output = get_all_layer_outputs(data_file) # return the same thing\n",
    "decoded_imgs = autoencoder.predict(data_file)\n",
    "\n",
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[43,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[44,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster EQ', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[45,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[43,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[44,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 18)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize=18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[45,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-EQ.png', dpi=100, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6c865-6715-4321-b573-55e6998cba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[353,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[354,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster CT1', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[355,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[353,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[354,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 18)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[355,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-CT1.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfa3f0-4f37-426b-b729-9b040894cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[1169,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[1170,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster ET', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[1171,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[1169,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[1170,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 20)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[1171,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-ET.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2455d0-5590-4b47-b51f-32033b7c71e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[2342,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[2343,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster CT2', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[2344,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[2342,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[2343,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 20)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[2344,:,:,0], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-CT2.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9243c6-82b7-42af-b81f-2f58e26490ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
