{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Download Notebook\n",
    "\n",
    "*Important Note:* This notebook runs using a different environment than this project's computational notebook. ObsPy is required, along with numpy and matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zali et al. 2024 pulls horizontal seismic data from a single horizontal component from a single station, demeaned and detrended but not converted from instrument response. The data is pulled from March 12 to June 24, ~104 days, beginning 7 days before the Geldingadalir eruption began. The data is also downsampled to the minimum sampling rate necessary to observe the local volcanic tremor.\n",
    "\n",
    "------------------\n",
    "\n",
    "This notebook will download 100 days of data, beginning on March 1st, 2005 and ending June 9th, 2005, from sensor CC.STD of the Cascade Chain Volcano Monitoring network, located on Mount St. Helens on Studebaker Ridge. Mount St. Helens had a series of eruptions of ash and steam between 2004 and 2008, but this will focus on the second explosive eruption on March 8th, 2005 that was preceeded by seismic activity. https://www.usgs.gov/volcanoes/mount-st.-helens/science/2004-2008-renewed-volcanic-activity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting obspy\n",
      "  Using cached obspy-1.4.1.tar.gz (17.0 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy>=1.20 (from obspy)\n",
      "  Downloading numpy-2.1.2-cp311-cp311-macosx_14_0_x86_64.whl.metadata (60 kB)\n",
      "Collecting scipy>=1.7 (from obspy)\n",
      "  Downloading scipy-1.14.1-cp311-cp311-macosx_14_0_x86_64.whl.metadata (60 kB)\n",
      "Collecting matplotlib>=3.3 (from obspy)\n",
      "  Downloading matplotlib-3.9.2-cp311-cp311-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
      "Collecting lxml (from obspy)\n",
      "  Downloading lxml-5.3.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: setuptools in /Users/KatarzynaPerks/Documents/GitHub/kperks_Geldingadalir/.conda/lib/python3.11/site-packages (from obspy) (75.1.0)\n",
      "Collecting sqlalchemy<2 (from obspy)\n",
      "  Downloading SQLAlchemy-1.4.54-cp311-cp311-macosx_10_9_universal2.whl.metadata (10 kB)\n",
      "Requirement already satisfied: decorator in /Users/KatarzynaPerks/Documents/GitHub/kperks_Geldingadalir/.conda/lib/python3.11/site-packages (from obspy) (5.1.1)\n",
      "Collecting requests (from obspy)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib>=3.3->obspy)\n",
      "  Downloading contourpy-1.3.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib>=3.3->obspy)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib>=3.3->obspy)\n",
      "  Downloading fonttools-4.54.1-cp311-cp311-macosx_10_9_universal2.whl.metadata (163 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib>=3.3->obspy)\n",
      "  Downloading kiwisolver-1.4.7-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/KatarzynaPerks/Documents/GitHub/kperks_Geldingadalir/.conda/lib/python3.11/site-packages (from matplotlib>=3.3->obspy) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib>=3.3->obspy)\n",
      "  Downloading pillow-11.0.0-cp311-cp311-macosx_10_10_x86_64.whl.metadata (9.1 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib>=3.3->obspy)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/KatarzynaPerks/Documents/GitHub/kperks_Geldingadalir/.conda/lib/python3.11/site-packages (from matplotlib>=3.3->obspy) (2.9.0)\n",
      "Collecting greenlet!=0.4.17 (from sqlalchemy<2->obspy)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->obspy)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-macosx_10_9_x86_64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->obspy)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->obspy)\n",
      "  Using cached urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->obspy)\n",
      "  Using cached certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/KatarzynaPerks/Documents/GitHub/kperks_Geldingadalir/.conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.3->obspy) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp311-cp311-macosx_10_12_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.1.2-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp311-cp311-macosx_14_0_x86_64.whl (25.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.5/25.5 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-1.4.54-cp311-cp311-macosx_10_9_universal2.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lxml-5.3.0-cp311-cp311-macosx_10_9_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-macosx_10_9_x86_64.whl (124 kB)\n",
      "Downloading contourpy-1.3.0-cp311-cp311-macosx_10_9_x86_64.whl (266 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.54.1-cp311-cp311-macosx_10_9_universal2.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-macosx_11_0_universal2.whl (272 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading kiwisolver-1.4.7-cp311-cp311-macosx_10_9_x86_64.whl (65 kB)\n",
      "Downloading pillow-11.0.0-cp311-cp311-macosx_10_10_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Building wheels for collected packages: obspy\n",
      "  Building wheel for obspy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for obspy: filename=obspy-1.4.1-cp311-cp311-macosx_10_13_x86_64.whl size=14109340 sha256=4057d547300c254192d734f38abb8d3484d321ba9a4f5a686c67b353aff2530a\n",
      "  Stored in directory: /Users/KatarzynaPerks/Library/Caches/pip/wheels/48/ad/ea/3a907122ce8a6d7e51485862ad0af11d123be891f283e50bb8\n",
      "Successfully built obspy\n",
      "Installing collected packages: urllib3, pyparsing, pillow, numpy, lxml, kiwisolver, idna, greenlet, fonttools, cycler, charset-normalizer, certifi, sqlalchemy, scipy, requests, contourpy, matplotlib, obspy\n",
      "Successfully installed certifi-2024.8.30 charset-normalizer-3.4.0 contourpy-1.3.0 cycler-0.12.1 fonttools-4.54.1 greenlet-3.1.1 idna-3.10 kiwisolver-1.4.7 lxml-5.3.0 matplotlib-3.9.2 numpy-2.1.2 obspy-1.4.1 pillow-11.0.0 pyparsing-3.2.0 requests-2.32.3 scipy-1.14.1 sqlalchemy-1.4.54 urllib3-2.2.3\n"
     ]
    }
   ],
   "source": [
    "!pip install obspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import UTCDateTime as utc\n",
    "from obspy.clients.fdsn import Client\n",
    "client = Client('IRIS')\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(st, buffer, freq, max_target_frequency): #freq is the original sampling frequency\n",
    "    st.merge(fill_value='interpolate')\n",
    "    tr = st[0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The seismic data is downloaded from the IRIS/Earthscope Database using ObsPy. The data downloads as a trace, an array of data with attached metadata, which is then packaged into a stream, which can contain multiple traces. The daily seismic data records are then saved as mseed files, which preserve this data+metadata structure, but requires ObsPy or other specialized software to open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data: File exists\n",
      "mkdir: data/raw: File exists\n",
      "Downloading data from 2005-03-01T00:00:00.000000Z to 2005-06-09T00:00:00.000000Z\n",
      "data download complete, saved to /Users/KatarzynaPerks/Documents/GitHub/kperks_Geldingadalir/notebooks/data/raw/\n"
     ]
    }
   ],
   "source": [
    "#creating variables to download data\n",
    "starttime = utc('2005-03-01T00:00:00')\n",
    "endtime = starttime + 100 * (60*60*24)\n",
    "\n",
    "#also add a buffer to both ends to chop off once the data has been filtered\n",
    "#and downsampled, kind of arbitrary length, 5% of a day (default ObsPy taper length)\n",
    "buffer = 60*60*24*0.05 #seconds\n",
    "\n",
    "net = 'CC'\n",
    "sta = 'STD'\n",
    "loc = '*' #wildcard, generally don't care about location code\n",
    "cha = 'BHN' #horizontal component, as used in Zali et al\n",
    "\n",
    "#create folder for numpy streams to go into and initialize filepath\n",
    "!mkdir data\n",
    "!mkdir data/raw\n",
    "filepath = os.getcwd() + '/data/raw/'\n",
    "\n",
    "#create arrays to save dates\n",
    "dates = np.array([])\n",
    "\n",
    "print(f'Downloading data from {starttime} to {endtime}')\n",
    "#download the data piecemeal, here by day\n",
    "for day in range(100):\n",
    "    tr_length = 24*60*60\n",
    "\n",
    "    try:\n",
    "        #actually downloading\n",
    "        st = client.get_waveforms(network=net,\n",
    "                     station=sta,\n",
    "                     location=loc,\n",
    "                     channel=cha,\n",
    "                     starttime=starttime-buffer,\n",
    "                     endtime=starttime+buffer+tr_length)\n",
    "\n",
    "        #instrument sampling rate (hz)\n",
    "        freq = st[0].stats.sampling_rate\n",
    "\n",
    "        #merge traces within stream, linearly interpolating any gaps\n",
    "        st.merge(fill_value='interpolate')\n",
    "    \n",
    "        #generate filename, day number in front for convenience of reading in\n",
    "        name = str(day+1)+'_sthelens.mseed'\n",
    "    \n",
    "        #save data as mseed, standard for storing seismic data. Preserves metadata and time series info\n",
    "        st.write(filepath+name, format='MSEED')\n",
    "\n",
    "        #adding date\n",
    "        dates = np.append(dates, starttime.date)\n",
    "\n",
    "    except FDSNNoDataException:\n",
    "        print(f'No data available for {starttime.date()}')\n",
    "    \n",
    "\n",
    "        starttime += tr_length\n",
    "\n",
    "\n",
    "#save dates list for future use\n",
    "np.save(filepath+'date_list.csv', dates)\n",
    "\n",
    "print(f'data download complete, saved to {filepath}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Data Modalities and Formats\n",
    "\n",
    "#### Data Modalities\n",
    "The dataset consists of seismic data collected from a single horizontal component (BHN) of the CC.STD station located on Mount St. Helens. The data is recorded continuously over a period of 100 days, capturing the seismic activity before, during, and after the steam and ash eruption.\n",
    "\n",
    "#### Data Formats\n",
    "1. **MSEED (Mini-SEED) Files**:\n",
    "    - The seismic data is stored in Mini-SEED format, which is a compact binary format used for storing time series data. Each file contains a day's worth of seismic data, including metadata such as the sampling rate and station information.\n",
    "    - Example file name: `1_sthelens.mseed`, `2_sthelens.mseed`, ..., `100_sthelens.mseed`.\n",
    "2. **Numpy Arrays**:\n",
    "    - The dates corresponding to each day's seismic data are stored in a numpy array and saved as a CSV file (`date_list.csv`). This array helps in mapping the MSEED files to their respective dates.\n",
    "    - Example: `dates = np.array([datetime.date(2005, 3, 1), datetime.date(2005, 3, 2), ...])`.\n",
    "\n",
    "#### Data Processing\n",
    "- The raw seismic data is downloaded using the ObsPy library from the IRIS/Earthscope Database.\n",
    "- The data is merged and interpolated to fill any gaps, ensuring a continuous time series.\n",
    "- The processed data is saved in the MSEED format, preserving both the time series and metadata.\n",
    "\n",
    "This structured approach ensures that the seismic data is well-organized and easily accessible for further analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example data from 100_sthelens.mseed\n",
      "               network: CC\n",
      "               station: STD\n",
      "              location: \n",
      "               channel: BHN\n",
      "             starttime: 2005-02-28T22:48:00.000000Z\n",
      "               endtime: 2005-03-02T01:12:00.000000Z\n",
      "         sampling_rate: 50.0\n",
      "                 delta: 0.02\n",
      "                  npts: 4752001\n",
      "                 calib: 1.0\n",
      "_fdsnws_dataselect_url: http://service.iris.edu/fdsnws/dataselect/1/query\n",
      "               _format: MSEED\n",
      "                 mseed: AttribDict({'dataquality': 'M', 'number_of_records': 3282, 'encoding': 'STEIM1', 'byteorder': '>', 'record_length': 512, 'filesize': 11978752})\n",
      "            processing: ['ObsPy 1.4.1: trim(endtime=UTCDateTime(2005, 3, 2, 1, 12)::fill_value=None::nearest_sample=True::pad=False::starttime=UTCDateTime(2005, 2, 28, 22, 48))']\n",
      "\n",
      "Example data from 100_sthelens.mseed\n",
      "[353322 349615 345409 ... 346392 340573 335078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display some data from the mseed file\n",
    "print(f'Example data from {name}')\n",
    "print(st[0].stats)\n",
    "print()\n",
    "\n",
    "# display the numpy array\n",
    "print(f'Example data from {name}')\n",
    "print(st[0].data)\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
