{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "855ba09c",
   "metadata": {},
   "source": [
    "# Set up your environment\n",
    "\n",
    "Use the mlgeo enviroment from class\n",
    "\n",
    "Use `ClusTremor-main/requirements.txt` for additional setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os, re, glob\n",
    "import math\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dropout, Reshape \n",
    "from tensorflow.keras.layers import Bidirectional, BatchNormalization, ZeroPadding1D, Conv2DTranspose\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.optimizers import SGD, Adam, schedules\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from tensorflow.keras.initializers import VarianceScaling\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_palette('muted')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef79091",
   "metadata": {},
   "source": [
    "# Load data and split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5e562e-458d-4f4d-98ad-afc1778647c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Step 1: Load data\n",
    "print(\"Beginning to load file...\")\n",
    "\n",
    "# Load the seismic data (adjust file path as needed)\n",
    "data_file = np.load(\"Input.npy\", mmap_mode='r', allow_pickle=True)\n",
    "\n",
    "print(\"File loaded\")\n",
    "\n",
    "# Step 2: Split data into train and test sets\n",
    "print(\"Split data into training and testing sets\")\n",
    "train_data, test_data = train_test_split(data_file, test_size=0.2, random_state=46, shuffle=True)\n",
    "\n",
    "print('Size of data_file:', data_file.shape)\n",
    "print('Size of train set:', train_data.shape)\n",
    "print('Size of test set:', test_data.shape)\n",
    "\n",
    "# Step 3: Convert the data into PyTorch tensors\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "test_data_tensor = torch.tensor(test_data, dtype=torch.float32)\n",
    "\n",
    "# If the data has more dimensions, you can reshape or modify it as needed, but\n",
    "# this will depend on the shape of your `Input.npy` file.\n",
    "\n",
    "# Example (assuming 4D input with channels, height, and width):\n",
    "# train_data_tensor = train_data_tensor.view(-1, 1, height, width)\n",
    "# test_data_tensor = test_data_tensor.view(-1, 1, height, width)\n",
    "\n",
    "# Step 4: Prepare DataLoader for batching\n",
    "batch_size = 32\n",
    "\n",
    "# Create TensorDataset and DataLoader for training and testing sets\n",
    "train_dataset = TensorDataset(train_data_tensor, train_data_tensor)  # (input, target) both are the same for autoencoder\n",
    "test_dataset = TensorDataset(test_data_tensor, test_data_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Data is now ready for training in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e4850-cc71-4419-a0f0-641ba43f765a",
   "metadata": {},
   "source": [
    "# Autoencoder architecture construction\n",
    "\n",
    "Import the dependencies first!\n",
    "!pip install torch\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f58b71a-84ff-417c-8261-54b91ce52507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "# Set the seed for reproducibility\n",
    "sd = 46\n",
    "torch.manual_seed(sd)\n",
    "\n",
    "# Function to calculate \"same\" padding for strided convolutions\n",
    "def calculate_same_padding(kernel_size, stride):\n",
    "    return ((stride - 1) + (kernel_size - 1)) // 2\n",
    "\n",
    "# Define the autoencoder model\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        # Encoder layers with manually calculated \"same\" padding\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=(7, 5), stride=2, padding=(calculate_same_padding(7, 2), calculate_same_padding(5, 2)))\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(5, 3), stride=2, padding=(calculate_same_padding(5, 2), calculate_same_padding(3, 2)))\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(5, 3), stride=2, padding=(calculate_same_padding(5, 2), calculate_same_padding(3, 2)))\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(5, 3), stride=2, padding=(calculate_same_padding(5, 2), calculate_same_padding(3, 2)))\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 6 * 8, 24)  # Adjusted based on conv output\n",
    "        self.fc2 = nn.Linear(24, 3072)\n",
    "\n",
    "        # Decoder layers\n",
    "        self.fc3 = nn.Linear(3072, 64 * 6 * 8)  # Adjust based on the shape before flattening\n",
    "        self.conv_transpose1 = nn.ConvTranspose2d(64, 32, kernel_size=(5, 3), stride=2, padding=(2, 1), output_padding=(1, 1))  # Adjust output_padding\n",
    "        self.conv_transpose2 = nn.ConvTranspose2d(32, 16, kernel_size=(5, 3), stride=2, padding=(2, 1), output_padding=(1, 1))\n",
    "        self.conv_transpose3 = nn.ConvTranspose2d(16, 8, kernel_size=(5, 3), stride=2, padding=(2, 1), output_padding=(1, 1))\n",
    "        self.conv_transpose4 = nn.ConvTranspose2d(8, 1, kernel_size=(7, 5), stride=2, padding=(3, 2), output_padding=(1, 1))  # Adjust padding/output_padding\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x = F.elu(self.conv1(x))\n",
    "        x = F.elu(self.conv2(x))\n",
    "        x = F.elu(self.conv3(x))\n",
    "        x = F.elu(self.conv4(x))\n",
    "\n",
    "        # Save shape for later use in decoder\n",
    "        shape_before_flattening = x.shape\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = self.flatten(x)\n",
    "        encoded = F.elu(self.fc1(x))\n",
    "        x = F.elu(self.fc2(encoded))\n",
    "\n",
    "        # Decoder\n",
    "        x = F.elu(self.fc3(x))\n",
    "        x = x.view(-1, 64, 6, 8)  # Reshape to the shape before flattening\n",
    "        x = F.elu(self.conv_transpose1(x))\n",
    "        x = F.elu(self.conv_transpose2(x))\n",
    "        x = F.elu(self.conv_transpose3(x))\n",
    "        decoded = self.conv_transpose4(x)  # No activation for output layer\n",
    "\n",
    "        return decoded, encoded\n",
    "\n",
    "\n",
    "# Create model instance\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "autoencoder.to(device)\n",
    "\n",
    "# Ensure that the input data is on the same device (for example, random input)\n",
    "dummy_input = torch.randn(1, 1, 96, 128).to(device)  # Simulate a batch of size 1\n",
    "\n",
    "# Now use torchinfo for the summary\n",
    "summary(autoencoder, input_size=(1, 1, 96, 128))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ebb90-94ed-4ffd-8627-3ca2b0deff1b",
   "metadata": {},
   "source": [
    "# Initial training phase: Pretraining the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb6564b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Define constants\n",
    "NUM_OF_EPOCHS = 50\n",
    "initial_lr = 0.001\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.5\n",
    "patience = 30\n",
    "\n",
    "# Initialize model, optimizer, and scheduler\n",
    "model = Autoencoder().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=initial_lr)\n",
    "scheduler = ExponentialLR(optimizer, gamma=decay_rate**(1 / decay_steps))\n",
    "\n",
    "# Setup CSV logger\n",
    "csv_log = {'epoch': [], 'train_loss': [], 'val_loss': [], 'learning_rate': []}\n",
    "\n",
    "# Early stopping parameters\n",
    "best_val_loss = float('inf')\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Training loop with early stopping and logging\n",
    "for epoch in range(NUM_OF_EPOCHS):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for data, _ in train_loader:\n",
    "        \n",
    "        data = data.squeeze().unsqueeze(1)  # Remove the extra dimension\n",
    "        inputs = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = model(inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            \n",
    "            #data = data.unsqueeze(1)\n",
    "            data = data.squeeze().unsqueeze(1)  # Ensure correct shape\n",
    "            inputs = data.to(device)\n",
    "            outputs, _ = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Average losses\n",
    "    train_loss /= len(train_loader)\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Log values\n",
    "    current_lr = scheduler.get_last_lr()[0]\n",
    "    csv_log['epoch'].append(epoch + 1)\n",
    "    csv_log['train_loss'].append(train_loss)\n",
    "    csv_log['val_loss'].append(val_loss)\n",
    "    csv_log['learning_rate'].append(current_lr)\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < best_val_loss:\n",
    "        print(f'Val loss decreased from {best_val_loss:.4f} to {val_loss:.4f}')\n",
    "        best_val_loss = val_loss\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= patience:\n",
    "            print(f\"Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "    # Print progress\n",
    "    print(f\"Epoch {epoch+1}/{NUM_OF_EPOCHS}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, LR: {current_lr:.6f}\")\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "# Save the CSV log\n",
    "pd.DataFrame(csv_log).to_csv('pretrain_log.csv', index=False)\n",
    "\n",
    "end_time = time.time()\n",
    "pretraining_ac_run_time = end_time - start_time\n",
    "print(f\"Training completed in {pretraining_ac_run_time:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512cbed-9eae-492a-b841-0b39131536a5",
   "metadata": {},
   "source": [
    "# Evaluate autoencoder reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936d9d0-7330-4320-82ff-4e89648ce8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('pretrain_log.csv')\n",
    "fig= plt.figure(figsize=(7, 5))\n",
    "plt.plot(df['epoch'],df['train_loss'], color='b',label='Training Loss', linewidth=3.0)\n",
    "plt.plot(df['epoch'],df['val_loss'], color='darkorange',label='Validation Loss', linewidth=3.0)\n",
    "\n",
    "plt.ylabel('Loss', fontsize= 18)\n",
    "plt.xlabel('Epoch', fontsize= 18)\n",
    "plt.title('Reconstruction loss of the autoencoder', fontsize= 18)\n",
    "plt.yticks (fontsize= 18)\n",
    "plt.xticks (fontsize= 18)\n",
    "\n",
    "plt.legend(loc= 1, frameon= False, fontsize= 18)\n",
    "plt.tight_layout()\n",
    "plt.show ()\n",
    "fig.savefig ( 'ReconstructionLoss.png', dpi= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa632679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to start from epoch 3\n",
    "df_filtered = df[df['epoch'] >= 3]\n",
    "\n",
    "# Plot the training and validation loss\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "plt.plot(df_filtered['epoch'], df_filtered['train_loss'], color='b', label='Training Loss', linewidth=3.0)\n",
    "plt.plot(df_filtered['epoch'], df_filtered['val_loss'], color='darkorange', label='Validation Loss', linewidth=3.0)\n",
    "\n",
    "plt.ylabel('Loss', fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=18)\n",
    "plt.title('Reconstruction loss of the autoencoder (Starting from Epoch 3)', fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "plt.xticks(fontsize=18)\n",
    "\n",
    "plt.legend(loc=1, frameon=False, fontsize=18)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig('ReconstructionLoss_from_epoch_3.png', dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec57e47-07ea-4e45-81e7-d30efd3bc952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict\n",
    "torch.save(model.state_dict(), 'autoencoder-model.pth')\n",
    "\n",
    "# Re-import or re-define the Autoencoder class\n",
    "autoencoder = Autoencoder()  # Instantiate the model\n",
    "autoencoder.load_state_dict(torch.load('autoencoder-model.pth'))  # Load the state_dict\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "autoencoder.to(device)\n",
    "\n",
    "# Set the model to evaluation mode if you're testing or inferring\n",
    "autoencoder.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1caeb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(data_file)  # Convert to PyTorch tensor\n",
    "data_tensor = data_tensor.unsqueeze(1)  # Adds a dimension at position 1\n",
    "\n",
    "data_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e508f0-1ad1-4309-a41f-5739b8f6fa7d",
   "metadata": {},
   "source": [
    "### Autoencoder input-output visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e01374-a800-49ce-9213-5e3dded6f220",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoded_imgs, _ = autoencoder(data_tensor.float().to(device))\n",
    "\n",
    "\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "s = 300\n",
    "e= 305\n",
    "n = e-s\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(s,e):\n",
    "    \n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i-s + 1)\n",
    "    librosa.display.specshow(data_file[i,:,:], alpha=None, cmap='hot', antialiased=True)\n",
    "    plt.colorbar ()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i-s + 1 + n)\n",
    "    librosa.display.specshow(decoded_imgs.cpu().detach().numpy()[i,0, :,:], alpha=None, cmap='hot', antialiased=True)\n",
    "    plt.colorbar ()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f604a8d6-4a34-43c7-81e3-ef55d39ba8a9",
   "metadata": {},
   "source": [
    "## Kmeans clustering based on extracted features from the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64671bcb-0ff8-414c-aacf-fa7ce2e18424",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs, encoded_imgs = autoencoder(data_tensor.float().to(device))\n",
    "\n",
    "kmeans = KMeans(n_clusters=1, random_state=46, n_init=20).fit(encoded_imgs.cpu().detach().numpy())\n",
    "y = kmeans.predict(encoded_imgs.cpu().detach().numpy())\n",
    "\n",
    "def plotter(S, y):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    \n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    plt.scatter(S[y == 0, 0], S[y == 0, 1],color='navy', alpha=.5, lw=lw, s=100)\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "    f.savefig ('Tnse-km-n1', dpi= 100,bbox_inches = \"tight\")\n",
    "\n",
    "    return f, ax\n",
    "\n",
    "enc = encoded_imgs.cpu().detach().numpy()\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n",
    "plotter(redu, y) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bc9c74",
   "metadata": {},
   "source": [
    "TODO: this plot doesn't look like the paper's plot\n",
    "This will make the following images look different from the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfcc610-b758-430f-8159-505dcad5d000",
   "metadata": {},
   "source": [
    "# Determining optimal number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5a5528-9064-4cee-b5b9-7f246de16eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "cal = []\n",
    "K = range(2,16)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=20).fit(encoded_imgs.cpu().detach().numpy())\n",
    "    labelskm = kmeans.predict(encoded_imgs.cpu().detach().numpy())\n",
    "    cal.append(calinski_harabasz_score(encoded_imgs.cpu().detach().numpy(), labelskm))\n",
    "fig= plt.figure(figsize=(7, 5))\n",
    "plt.plot(K, cal, 'bx-')\n",
    "plt.xlabel('Number of clusters',fontsize= 18)\n",
    "plt.ylabel('Calinski-Harabasz score',fontsize= 18)\n",
    "plt.title('Calinski-Harabasz Score Elbow for K-means Clustering',fontsize= 18)\n",
    "plt.yticks (fontsize= 18)\n",
    "plt.xticks (fontsize= 18)\n",
    "plt.axvline(x = 4, color = 'black')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "fig.savefig ( 'Calinski score.png', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e565b504-f0a8-4324-b24c-4a21aab6f345",
   "metadata": {},
   "source": [
    "# T-sne visualizations of seismic event clusters in feature domain after pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5ec66b-cd4d-426f-9fd6-255078c97428",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = encoded_imgs.cpu().detach().numpy()\n",
    "kmeans = KMeans(n_clusters=4, random_state=46, n_init=20).fit(encoded_imgs.cpu().detach().numpy())\n",
    "y = kmeans.predict(enc)\n",
    "\n",
    "def plotter(S, y, target_names):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    # choose a color palette with seaborn.\n",
    "    colors = [ 'red', 'mediumblue','darkorange','turquoise','lime', 'turquoise', 'darkorange','lawngreen', 'red', 'saddlebrown']\n",
    "    \n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    for color, i, target_name in zip(colors, [3,0, 1,2], target_names):\n",
    "        plt.scatter(S[y == i, 0], S[y == i, 1], color=color, alpha=.5, lw=lw, s=100, label=target_name)\n",
    "    plt.legend(loc='lower left', shadow=False, scatterpoints=1, prop={'size': 26})\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "    f.savefig ('Tnse-km-n4', dpi= 100,bbox_inches = \"tight\")\n",
    "\n",
    "    return f, ax\n",
    "\n",
    "enc = encoded_imgs.cpu().detach().numpy()\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n",
    "target_names = ['cluster 1', 'cluster 2', 'cluster 3', 'cluster 4']\n",
    "plotter(redu, y, target_names) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc368d8-35b2-4ce4-bd45-66a0ac5c3661",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Loading the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3f4cf-8b29-4ab4-bdaa-e32250578df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tensor = torch.tensor(data_file)  # Convert to PyTorch tensor\n",
    "data_tensor = data_tensor.unsqueeze(1).to(device)  # Adds a dimension at position 1\n",
    "\n",
    "\n",
    "# Assuming autoencoder and data_file are already defined\n",
    "autoencoder.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define a dictionary to store layer outputs\n",
    "layer_outputs = {}\n",
    "\n",
    "# Function to create hooks for capturing the outputs\n",
    "def get_layer_output_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        layer_outputs[name] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks on each layer you want to capture (starting from layer 1 as in your example)\n",
    "for idx, layer in enumerate(list(autoencoder.children())[1:], start=1):\n",
    "    layer.register_forward_hook(get_layer_output_hook(f'layer_{idx}'))\n",
    "\n",
    "# Run a forward pass with `data_file` to capture the outputs\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    data = torch.tensor(data_tensor, dtype=torch.float32)  # Convert data_file to tensor\n",
    "    autoencoder(data)  # Run data through the model to capture intermediate outputs\n",
    "\n",
    "# Display the outputs\n",
    "for name, output in layer_outputs.items():\n",
    "    print(f\"{name} output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6d620-b779-4741-acf2-d6846c24949c",
   "metadata": {},
   "source": [
    "# Integrating clustering layer into autoencoder bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2a704a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Set seed for reproducibility\n",
    "seed = 46\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Initialize Xavier initializer (same as GlorotUniform in TensorFlow)\n",
    "initializer = nn.init.xavier_uniform_\n",
    "n_clusters = 4 # Set desired number of clusters\n",
    "\n",
    "\n",
    "# Define the clustering layer in PyTorch\n",
    "class ClusteringLayer(nn.Module):\n",
    "    def __init__(self, n_clusters, input_dim, alpha=1.0):\n",
    "        super(ClusteringLayer, self).__init__()\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Initialize the cluster centers\n",
    "        self.clusters = nn.Parameter(torch.Tensor(n_clusters, input_dim))\n",
    "        # Define cluster centers as a trainable parameter\n",
    "        \n",
    "        initializer(self.clusters)  # Xavier initialization\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        print(inputs.shape)\n",
    "        self.clusters = self.clusters.to(inputs.device)\n",
    "        # Compute the soft assignment q\n",
    "        q = 1.0 / (1.0 + (torch.sum((inputs.unsqueeze(1) - self.clusters) ** 2, dim=2) / self.alpha))\n",
    "        q = q ** ((self.alpha + 1.0) / 2.0)\n",
    "        q = q / torch.sum(q, dim=1, keepdim=True)  # Normalize to get probabilities per cluster\n",
    "        return q\n",
    "\n",
    "# Define the full model with the clustering layer on top of the autoencoder\n",
    "class ClusteredAutoencoder(nn.Module):\n",
    "    def __init__(self, autoencoder, n_clusters):\n",
    "        super(ClusteredAutoencoder, self).__init__()\n",
    "        self.autoencoder = autoencoder\n",
    "        # Clustering layer connected to the output of the encoder\n",
    "        self.clustering_layer = ClusteringLayer(n_clusters=n_clusters, input_dim=24)  # Match to `encoded` dimension\n",
    "\n",
    "    def forward(self, x):\n",
    "        decoded, encoded = self.autoencoder(x)\n",
    "        q = self.clustering_layer(encoded)  # Cluster assignments\n",
    "        return decoded, q  # Return both decoded output and cluster assignments\n",
    "\n",
    "# Instantiate the models\n",
    "n_clusters = 4  # Set desired number of clusters\n",
    "model = ClusteredAutoencoder(autoencoder, n_clusters=n_clusters)\n",
    "\n",
    "# Define the KL-divergence loss function\n",
    "def kld_loss(q, p):\n",
    "    return F.kl_div(q.log(), p, reduction='batchmean')\n",
    "\n",
    "# Example optimizer setup\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Training loop placeholder\n",
    "def train(model, data_loader, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for inputs, _ in data_loader:\n",
    "            decoded, q = model(inputs)\n",
    "            # Target distribution p, here using a sample softmax normalization of q as a placeholder\n",
    "            p = (q ** 2) / torch.sum(q, dim=0)\n",
    "            p = p / torch.sum(p, dim=1, keepdim=True)\n",
    "            \n",
    "            # Calculate the losses\n",
    "            reconstruction_loss = F.mse_loss(decoded, inputs)\n",
    "            clustering_loss = kld_loss(q, p)\n",
    "            total_loss = 0.1 * clustering_loss + reconstruction_loss\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss.item():.4f}')\n",
    "\n",
    "# Visualize the model (can be printed or logged)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model.to(device)\n",
    "\n",
    "# Ensure that the input data is on the same device (for example, random input)\n",
    "dummy_input = torch.randn(1, 1, 96, 128).to(device)  # Simulate a batch of size 1\n",
    "\n",
    "# Now use torchinfo for the summary\n",
    "summary(model, input_size=(1, 1, 96, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3549ee2-a05b-4c8e-8b3f-ef5de83470b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import torch\n",
    "\n",
    "\n",
    "# Assuming autoencoder and data_file are already defined\n",
    "data_tensor = torch.tensor(data_file)  # Convert to PyTorch tensor\n",
    "data_tensor = data_tensor.unsqueeze(1).to(device)  # Adds a dimension at position 1\n",
    "\n",
    "autoencoder.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define a dictionary to store layer outputs\n",
    "layer_outputs = {}\n",
    "\n",
    "# Function to create hooks for capturing the outputs\n",
    "def get_layer_output_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        layer_outputs[name] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks on each layer you want to capture (starting from layer 1 as in your example)\n",
    "for idx, layer in enumerate(list(autoencoder.children())[1:], start=1):\n",
    "    layer.register_forward_hook(get_layer_output_hook(f'layer_{idx}'))\n",
    "\n",
    "# Run a forward pass with `data_file` to capture the outputs\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    data = data_tensor.float()  # Ensure data is in float32 format\n",
    "    autoencoder(data)  # Run data through the model to capture intermediate outputs\n",
    "\n",
    "# Display the outputs\n",
    "for name, output in layer_outputs.items():\n",
    "    print(f\"{name} output shape: {output.shape}\")\n",
    "\n",
    "n_clusters = 4  # Define the number of clusters\n",
    "\n",
    "# Step 1: Perform KMeans on the encoded output to initialize cluster centers\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=46, n_init=20)\n",
    "encoded_output = layer_outputs['layer_5'].cpu().detach().numpy()  # Assuming this is the encoded output\n",
    "y_pred = kmeans.fit_predict(encoded_output)\n",
    "y_pred_last = np.copy(y_pred)\n",
    "\n",
    "# Step 2: Set the KMeans cluster centers as initial weights in the clustering layer\n",
    "cluster_centers = torch.tensor(kmeans.cluster_centers_, dtype=torch.float32, device = device)\n",
    "\n",
    "# Assuming model.clustering_layer is the clustering layer in the PyTorch model\n",
    "model.clustering_layer.clusters.data = cluster_centers  # Directly assign cluster centers\n",
    "\n",
    "# Verify the initialization\n",
    "print(\"Number of clusters in KMeans model:\", kmeans.n_clusters)\n",
    "print(\"Number of clusters in clustering layer:\", model.clustering_layer.n_clusters)\n",
    "print(\"Assigned KMeans cluster centers as initial weights in the clustering layer.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f34c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs  = model(data_tensor.float().to(device))[0]\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "s = 300\n",
    "e= 305\n",
    "n = e-s\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(s,e):\n",
    "    \n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i-s + 1)\n",
    "    librosa.display.specshow(data_file[i,:,:], alpha=None, cmap='hot', antialiased=True)\n",
    "    plt.colorbar ()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i-s + 1 + n)\n",
    "    librosa.display.specshow(decoded_imgs.cpu().detach().numpy()[i,0, :,:], alpha=None, cmap='hot', antialiased=True)\n",
    "    plt.colorbar ()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534dbf3a-6ee3-4e02-98d9-c8733db0497e",
   "metadata": {},
   "source": [
    "# Finetuning pre-trained model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2e909d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# Parameters for fine-tuning\n",
    "batch_size = 32\n",
    "tol = 0.0001  # tolerance threshold for early stopping\n",
    "loss_value = 0\n",
    "index = 0\n",
    "maxiter = 300\n",
    "update_interval = 200\n",
    "index_array = np.arange(data_file.shape[0])\n",
    "y_pred_last = np.zeros(data_file.shape[0])\n",
    "\n",
    "data_tensor = torch.tensor(data_file, dtype=torch.float32)\n",
    "data_tensor = data_tensor.unsqueeze(1).to(device)  # Adds a dimension at position 1\n",
    "\n",
    "# Define the target distribution function\n",
    "def target_distribution(q):\n",
    "    weight = q ** 2 / np.sum(q, axis=0)\n",
    "    return (weight.T / np.sum(weight, axis=1)).T\n",
    "\n",
    "# Fine-tuning loop\n",
    "for ite in range(maxiter):\n",
    "    print(f\"Iteration: {ite}\")\n",
    "    \n",
    "    # Update clustering target distribution periodically\n",
    "    if ite % update_interval == 0:\n",
    "        print(\"Updating target distribution\")\n",
    "        \n",
    "        # Forward pass to get cluster assignments\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            \n",
    "            _, q = model(data_tensor)\n",
    "       \n",
    "            q = q.cpu().numpy()  # Convert to numpy for further processing\n",
    "        \n",
    "        # Update the target distribution `p`\n",
    "        p = target_distribution(q)\n",
    "        y_pred = q.argmax(1)  # Get cluster assignments\n",
    "        \n",
    "        # Print loss and clustering information\n",
    "        print(f\"Iter {ite}: ; loss={round(loss_value, 5)}\")\n",
    "\n",
    "        # Check convergence criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        \n",
    "        if ite > 0 and delta_label < tol:\n",
    "            print(f\"Convergence achieved: delta_label {delta_label} < tol {tol}\")\n",
    "            break\n",
    "    \n",
    "    # Mini-batch training\n",
    "    start_idx = index * batch_size\n",
    "    end_idx = min((index + 1) * batch_size, data_file.shape[0])\n",
    "    idx = index_array[start_idx:end_idx]\n",
    "    \n",
    "    batch_data = data_tensor[idx]\n",
    "    batch_p = torch.tensor(p[idx], dtype=torch.float32, device = device)\n",
    "\n",
    "    # Zero gradients, forward pass, compute loss, backward pass, and update\n",
    "    optimizer.zero_grad()\n",
    "    decoded, q_batch = model(batch_data)\n",
    "    clustering_loss = F.kl_div(q_batch.log(), batch_p, reduction=\"batchmean\")\n",
    "    reconstruction_loss = F.mse_loss(decoded, batch_data)\n",
    "    total_loss = clustering_loss * 0.1 + reconstruction_loss\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update loss and index for next iteration\n",
    "    loss_value = total_loss.item()\n",
    "    index = (index + 1) % (data_file.shape[0] // batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9705825-856b-4645-a5aa-414155ef00a8",
   "metadata": {},
   "source": [
    "# T-sne visualizations of seismic event clusters in feature domain after finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea5f876-8994-4086-9074-ae0780173492",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()  # Set to evaluation mode\n",
    "\n",
    "# Define a dictionary to store layer outputs\n",
    "layer_outputs = {}\n",
    "\n",
    "# Function to create hooks for capturing the outputs\n",
    "def get_layer_output_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        layer_outputs[name] = output\n",
    "    return hook\n",
    "\n",
    "# Register hooks on each layer you want to capture (starting from layer 1 as in your example)\n",
    "for idx, layer in enumerate(list(autoencoder.children())[1:], start=1):\n",
    "    layer.register_forward_hook(get_layer_output_hook(f'layer_{idx}'))\n",
    "\n",
    "# Run a forward pass with `data_file` to capture the outputs\n",
    "with torch.no_grad():  # Disable gradient computation\n",
    "    data = data_tensor.float()  # Ensure data is in float32 format\n",
    "    autoencoder(data)  # Run data through the model to capture intermediate outputs\n",
    "\n",
    "y=y_pred\n",
    "\n",
    "def plotter(S, y, target_names):\n",
    "    '''\n",
    "    function to visualize the outputs of t-SNE\n",
    "    '''\n",
    "    # choose a color palette with seaborn.\n",
    "    colors = ['red', 'mediumblue','darkorange','turquoise', 'lawngreen', 'red', 'saddlebrown']\n",
    "    \n",
    "    lw = 2\n",
    "    # create a scatter plot.\n",
    "    f = plt.figure(figsize=(22, 10))\n",
    "    ax = f.add_subplot(111)\n",
    "    for color, i, target_name in zip(colors, [3,0, 1,2], target_names):\n",
    "        plt.scatter(S[y == i, 0], S[y == i, 1], color=color, alpha=0.5, lw=lw, s=100, label=target_name)\n",
    "    plt.legend(loc='lower left', shadow=False, scatterpoints=1, prop={'size': 26})\n",
    "    ax.axis('off')\n",
    "    ax.axis('tight') \n",
    "    plt.show()\n",
    "    f.savefig ('Tsne-km-n4-ft.png', dpi= 100,bbox_inches = \"tight\")\n",
    "    \n",
    "    return f, ax\n",
    "\n",
    "enc = layer_outputs['layer_5'].cpu().detach().numpy()\n",
    "from sklearn.manifold import TSNE\n",
    "redu = TSNE(random_state=123).fit_transform(enc)\n",
    "target_names = [ 'Earthquakes (EQ)','Continuous tremors 1 (CT1)', 'Episodic tremors (ET)', 'Continuous tremors 2 (CT2)' ]\n",
    "plotter(redu, y, target_names) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a10236-cc2f-48df-8ac5-7482e19f9412",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save the labels\n",
    "np.savetxt('km-n4-ft.txt', y, fmt='%i', delimiter=',')\n",
    "\n",
    "# Change the order of the cluster numbers (just for a nice representation)\n",
    "\n",
    "with open('km-n4-ft.txt', 'r') as file :\n",
    "  filedata = file.read()\n",
    "\n",
    "# Replace the target string\n",
    "filedata = filedata.replace('3', 'data_file')\n",
    "filedata = filedata.replace('2', '3')\n",
    "filedata = filedata.replace('1', '2')\n",
    "filedata = filedata.replace('0', '1')\n",
    "filedata = filedata.replace('data_file', '0')\n",
    "\n",
    "# Re-write the output\n",
    "with open('km-n4-ft.txt', 'w') as file:\n",
    "  file.write(filedata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eb231f-9bae-4f09-8adf-906789cec64d",
   "metadata": {},
   "source": [
    "### Visualizing cluster changes across time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a1b419-d268-47f7-a850-037dc1bd6b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "y= np.loadtxt ('km-n4-ft.txt')\n",
    "fig= plt.figure(figsize=(18, 4))\n",
    "ax = fig.add_subplot()\n",
    "x1=list(range(0,2390))\n",
    "colors = ['red', 'mediumblue','darkorange','turquoise']\n",
    "cmap_name = 'my_list'\n",
    "cmap = LinearSegmentedColormap.from_list(cmap_name, colors)\n",
    "ax.scatter (x1, y, c=y, cmap=cmap, s= 30, alpha=0.2)\n",
    "ax.set_yticks ([0, 1, 2,3])\n",
    "ax.set_yticklabels (['EQ','CT1', 'ET','CT2'], fontsize=18)\n",
    "plt.ylabel('Clusters', fontsize= 18)\n",
    "\n",
    "ax.set_xticks ([0,175,417,708,996,1117,1425,1782,2142,2390])\n",
    "ax.set_xticklabels (['12 March','19 March','30 March','15 April','27 April','2 May','15 May','30 May','14 June','24 June'], fontsize=16)\n",
    "ax.axvline (x=174, linewidth=4, color='black')\n",
    "ax.axvline (x=996, linewidth=4, color='black')\n",
    "ax.axvline (x=2127, linewidth=4, color='black')\n",
    "\n",
    "plt.xlim (0,2390)\n",
    "#plt.xlim (980,1020)\n",
    "plt.tight_layout()\n",
    "fig.savefig ( 'Temporal Cluster Changes.png', dpi= 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ff7eec-7915-4152-85ce-4aa2c978466f",
   "metadata": {},
   "source": [
    "# Cluster-wise autoencoder input-output visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782d73f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs[43,:,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a56f5-eea9-451d-a61d-3b6a480110f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "decoded_imgs, _ = autoencoder(data_tensor.float().to(device))\n",
    "decoded_imgs = decoded_imgs.cpu().detach().numpy()\n",
    "\n",
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[43,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[44,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster EQ', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[45,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[43,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[44,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 18)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize=18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[45,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks ([])\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-EQ.png', dpi=100, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6c865-6715-4321-b573-55e6998cba97",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[353,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[354,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster CT1', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[355,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[353,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[354,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 18)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[355,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-CT1.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cfa3f0-4f37-426b-b729-9b040894cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[1169,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[1170,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster ET', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[1171,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[1169,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[1170,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 20)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[1171,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-ET.png', dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7b2455d0-5590-4b47-b51f-32033b7c71e3",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "fig= plt.figure(figsize=(15, 5))\n",
    "spec = gridspec.GridSpec(2, 3)\n",
    "\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "\n",
    "librosa.display.specshow(data_file[2342,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax1.set(ylabel=None)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "\n",
    "librosa.display.specshow(data_file[2343,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax2.set(ylabel=None)\n",
    "\n",
    "fig.suptitle ('Cluster CT2', fontsize= 22)\n",
    "\n",
    "ax3 = fig.add_subplot(spec[0, 2])\n",
    "\n",
    "librosa.display.specshow(data_file[2344,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax3.set(ylabel=None)\n",
    "\n",
    "ax4 = fig.add_subplot(spec[1, 0])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[2342,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax4.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "plt.ylabel('Frequency (Hz)', fontsize= 18)\n",
    "\n",
    "ax5 = fig.add_subplot(spec[1, 1])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[2343,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax5.set(ylabel=None)\n",
    "ax5.set_xlabel(\"Time (min)\", fontsize= 20)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "ax6 = fig.add_subplot(spec[1, 2])\n",
    "\n",
    "librosa.display.specshow(decoded_imgs[2344,0,:,:], alpha=None, cmap='hot', antialiased=True,y_axis='linear', sr= 8, vmin=-1 , vmax=10)\n",
    "cbar= plt.colorbar(pad= 0.03)\n",
    "cbar.ax.tick_params(labelsize=18, rotation=0)\n",
    "freq =[0,1.33, 2.66, 4]\n",
    "labelsy = [1,2,3, 4]\n",
    "plt.yticks (freq, labelsy, fontsize= 18)\n",
    "ax6.set(ylabel=None)\n",
    "labelsx = [0,30,60]\n",
    "plt.xticks(np.arange(0,128, 63.999), labelsx, fontsize= 18)\n",
    "\n",
    "plt.tight_layout()    \n",
    "plt.savefig ('In&out-CT2.png', dpi=100)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
