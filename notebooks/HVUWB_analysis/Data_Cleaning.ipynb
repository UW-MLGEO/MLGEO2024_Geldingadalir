{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning/Processing Steps\n",
    "The data will be demeaned similar to Zali et al., using a more conservative downsample rate of 20 Hz, given volcanic tremor is typically between 1-9 Hz.\n",
    "\n",
    "*Read in mseed files <br>\n",
    "*Check all are the same length <br>\n",
    "*Demean and detrend <br>\n",
    "*Anti-alias filter and downsample data to 8 Hz from 100 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress the specific warning from obspy\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"The encoding specified in trace.stats.mseed.encoding does not match the dtype of the data.*\",\n",
    "    category=UserWarning,\n",
    "    module=\"obspy.io.mseed.core\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy import read\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "# Define the folder paths\n",
    "input_folder = os.getcwd() + '/data/raw'\n",
    "processed_folder = os.getcwd() + '/data/processed'\n",
    "os.makedirs(processed_folder, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Target sampling rate after downsampling\n",
    "target_sampling_rate = 8  # Hz\n",
    "\n",
    "length = np.array([])\n",
    "\n",
    "# Process each mseed file in the folder\n",
    "for file_path in glob.glob(f\"{input_folder}/*.mseed\"):\n",
    "    \n",
    "    # Read the file\n",
    "    st = read(file_path)\n",
    "    \n",
    "    # Demean, detrend, and downsample each trace\n",
    "    for tr in st:\n",
    "        tr.detrend(\"demean\")   # Remove mean\n",
    "        tr.detrend(\"linear\")   # Remove linear trend\n",
    "        tr.filter(\"lowpass\", freq=target_sampling_rate / 2)  # Anti-aliasing filter\n",
    "        tr.resample(target_sampling_rate)  # Downsample to 8 Hz\n",
    "        \n",
    "        # Normalize using Z-score normalization\n",
    "        tr_data_mean = np.mean(tr.data)\n",
    "        tr_data_std = np.std(tr.data)\n",
    "        tr.data = (tr.data - tr_data_mean) / tr_data_std  # Z-score normalization\n",
    "        \n",
    "    #add data length to array\n",
    "    length = np.append(length, len(tr.data))\n",
    "\n",
    "    # Save the processed data\n",
    "    output_file = os.path.join(processed_folder, os.path.basename(file_path))\n",
    "    st.write(output_file, format=\"MSEED\")\n",
    "    print(f'processed file: {output_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the lengths of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m lengths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(lengths)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Check if all files have the same length\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(lengths \u001b[38;5;241m==\u001b[39m \u001b[43mlengths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll files have the same length: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlengths[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m data points.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from obspy import read\n",
    "# import glob\n",
    "# import numpy as np\n",
    "\n",
    "# Define the processed folder path = output_folder\n",
    "processed_folder = os.getcwd() + '/data/processed'\n",
    "\n",
    "# Array to store the lengths of each file\n",
    "lengths = []\n",
    "\n",
    "# Check each processed file's length\n",
    "for file_path in glob.glob(f\"{processed_folder}/*.mseed\"):\n",
    "    # Read only metadata\n",
    "    st = read(file_path, headonly=True)\n",
    "    \n",
    "    # Extract the number of data points in each trace\n",
    "    for tr in st:\n",
    "        lengths.append(tr.stats.npts)\n",
    "\n",
    "# Convert to numpy array for easier analysis\n",
    "lengths = np.array(lengths)\n",
    "\n",
    "# Check if all files have the same length\n",
    "if np.all(lengths == lengths[0]):\n",
    "    print(f\"All files have the same length: {lengths[0]} data points.\")\n",
    "else:\n",
    "    print(\"Files have different lengths:\", lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~This is the correct number of points (+1) for 24 hours of data sampled at 25 Hz. The single extra point is a product of the decimation, will be removed in the preparing ai ready data notebook.~~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
