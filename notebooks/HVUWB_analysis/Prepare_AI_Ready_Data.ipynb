{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for the model used in the paper ##\n",
    "\n",
    "Read each file and segment them into one hour windows. Each file will contain 28,800 samples per hour at an 8 Hz sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy import read\n",
    "import glob\n",
    "import numpy as np\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "# Define the processed and output folder paths\n",
    "processed_folder = os.getcwd() + '/data/processed'\n",
    "segmented_output_folder = os.getcwd() + '/data/segmented'\n",
    "os.makedirs(segmented_output_folder, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Define the target segment duration (1 hour) in seconds\n",
    "segment_duration = 3600  # seconds\n",
    "\n",
    "# Process each processed file for segmentation\n",
    "for file_path in glob.glob(f\"{processed_folder}/*.mseed\"):\n",
    "    # Read the processed file\n",
    "    st = read(file_path)\n",
    "    \n",
    "    # Split each trace in the Stream object into one-hour segments\n",
    "    for tr in st:\n",
    "        start_time = tr.stats.starttime\n",
    "        end_time = tr.stats.endtime\n",
    "        segment_start = start_time\n",
    "\n",
    "        # Loop over each one-hour segment\n",
    "        while segment_start + segment_duration <= end_time:\n",
    "            # Define the end time for the current segment\n",
    "            segment_end = segment_start + segment_duration\n",
    "\n",
    "            # Slice the trace to create a one-hour segment\n",
    "            segment = tr.slice(starttime=segment_start, endtime=segment_end)\n",
    "            \n",
    "            # Format the filename for the segment\n",
    "            segment_filename = f\"{tr.stats.network}_{tr.stats.station}_{tr.stats.channel}_{segment_start.strftime('%Y%m%dT%H%M%S')}.mseed\"\n",
    "            segment_filepath = os.path.join(segmented_output_folder, segment_filename)\n",
    "\n",
    "            # Save the one-hour segment as a new file\n",
    "            segment.write(segment_filepath, format=\"MSEED\")\n",
    "            print(f'Saved segment file: {segment_filepath}')\n",
    "\n",
    "            # Move to the next hour\n",
    "            segment_start = segment_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Fourier Transform with the `specified window_length` and `hop_length parameters` to produce a spectrogram of size (96, 128) for each one-hour segment. The data is saved in `segmented_output_folder` from the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from obspy import read\n",
    "import librosa\n",
    "from scipy.signal import resample\n",
    "\n",
    "# Define directories\n",
    "input_folder = os.getcwd() + '/data/raw'\n",
    "processed_folder = os.getcwd() + '/data/processed'\n",
    "segmented_output_folder = os.getcwd() + '/data/segmented'\n",
    "os.makedirs(segmented_output_folder, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Define constants\n",
    "target_sampling_rate = 8  # Hz\n",
    "segment_duration = 3600  # 1 hour in seconds\n",
    "window_length = 256\n",
    "hop_length = 224\n",
    "target_shape = (96, 128)\n",
    "\n",
    "# Initialize an empty list to store spectrograms\n",
    "spectrogram_list = []\n",
    "\n",
    "# Step 1: Process each file in the input folder\n",
    "for file_path in glob.glob(f\"{input_folder}/*.mseed\"):\n",
    "    # Read the file\n",
    "    st = read(file_path)\n",
    "    \n",
    "    # Process each trace\n",
    "    for tr in st:\n",
    "        # Resample the data to 8 Hz (assuming original sampling rate was 100 Hz)\n",
    "        tr.resample(target_sampling_rate)\n",
    "        \n",
    "        # Split into one-hour segments (28,800 samples each)\n",
    "        start_time = tr.stats.starttime\n",
    "        end_time = tr.stats.endtime\n",
    "        segment_start = start_time\n",
    "\n",
    "        while segment_start + segment_duration <= end_time:\n",
    "            # Define the end time for the current segment\n",
    "            segment_end = segment_start + segment_duration\n",
    "\n",
    "            # Slice the trace to create a one-hour segment\n",
    "            segment = tr.slice(starttime=segment_start, endtime=segment_end)\n",
    "            \n",
    "            # Compute STFT for the segment\n",
    "            signal = segment.data\n",
    "            stft_result = librosa.stft(signal, n_fft=window_length, hop_length=hop_length, win_length=window_length)\n",
    "            spectrogram = np.abs(stft_result) ** 2\n",
    "\n",
    "            # Resize spectrogram to target shape\n",
    "            spectrogram_resized = librosa.util.fix_length(spectrogram, size=target_shape[1], axis=1)[:target_shape[0], :]\n",
    "\n",
    "            # Log transformation for normalization\n",
    "            spectrogram_log = np.log1p(spectrogram_resized)\n",
    "\n",
    "            # Save the spectrogram (you could save the result as needed)\n",
    "            segment_filename = f\"{tr.stats.network}_{tr.stats.station}_{tr.stats.channel}_{segment_start.strftime('%Y%m%dT%H%M%S')}.npy\"\n",
    "            segment_filepath = os.path.join(segmented_output_folder, segment_filename)\n",
    "            np.save(segment_filepath, spectrogram_log)\n",
    "            print(f'Saved spectrogram for segment: {segment_filepath}')\n",
    "\n",
    "            # Append the spectrogram to the list\n",
    "            spectrogram_list.append(spectrogram_log)\n",
    "\n",
    "            # Move to the next hour\n",
    "            segment_start = segment_end\n",
    "\n",
    "# Stack all spectrograms into a single numpy array and add batch and channel dimensions\n",
    "all_spectrograms = np.stack(spectrogram_list)\n",
    "all_spectrograms = all_spectrograms[:, np.newaxis, :, :]  # Shape: (batch_size, 1, 96, 128)\n",
    "print(f\"Shape of combined spectrogram array with batch and channel dimensions: {all_spectrograms.shape}\")\n",
    "\n",
    "# NOTE: FILE NAME IS HARD CODED HERE\n",
    "# Save the combined spectrogram array to Input.npy\n",
    "input_filepath = os.path.join(segmented_output_folder, \"Input.npy\")\n",
    "np.save(input_filepath, all_spectrograms)\n",
    "print(f'Saved combined spectrogram file: {input_filepath}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined spectrogram array with batch and channel dimensions: (1560, 1, 96, 128)\n",
      "Number of files processed: 1560\n",
      "Shape of combined spectrogram array Input.npy: (1560, 1, 96, 128)\n",
      "Number of files processed: 1560\n"
     ]
    }
   ],
   "source": [
    "#display information on Input.npy\n",
    "print(f\"Shape of combined spectrogram array with batch and channel dimensions: {all_spectrograms.shape}\")\n",
    "print(f\"Number of files processed: {all_spectrograms.shape[0]}\")\n",
    "\n",
    "# load Input.npy and display information for confirmation\n",
    "input_data_file_t = np.load(input_filepath)\n",
    "print(f\"Shape of combined spectrogram array Input.npy: {input_data_file_t.shape}\")\n",
    "print(f\"Number of files processed: {input_data_file_t.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Input shape is [all_spectrograms.shape[0], 1, 96, 128] where:\n",
    "\n",
    "all_spectrograms.shape[0]: batch size -> the number of hours of data processed\n",
    "1: input channel (grayscale or single-channel data)\n",
    "96: height (or time)\n",
    "128: width (or frequency)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
