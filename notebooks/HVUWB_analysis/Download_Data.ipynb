{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Download Notebook\n",
    "\n",
    "Zali et al. 2024 pulls horizontal seismic data from a single horizontal component from a single station, demeaned and detrended but not converted from instrument response. The data is pulled from March 12 to June 24, ~104 days, beginning 7 days before the Geldingadalir eruption began. The data is also downsampled to the minimum sampling rate necessary to observe the local volcanic tremor.\n",
    "\n",
    "*Important Note:* This notebook runs using a different environment than this project's computational notebook. ObsPy is required, along with numpy and matplotlib\n",
    "\n",
    "This notebook downloads 60 days of data, beginning 08/15/2024, from the HV.UWB sensor at the of the Hawaiian Volcano Observatory's network, located on the island of Hawaii.\n",
    "\n",
    "> Magma intruded beneath the ground near Makaopuhi Crater—a well-known magma storage region on Kīlauea’s middle East Rift Zone on September 14. HVO published a Status Report alerting the public and partners to the activity, which was accompanied by hundreds of earthquakes and ground deformation. \n",
    "\n",
    "https://www.usgs.gov/observatories/hvo/science/eruption-kilauea-middle-east-rift-zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import UTCDateTime as utc\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(st, buffer, freq, max_target_frequency): #freq is the original sampling frequency\n",
    "    st.merge(fill_value='interpolate')\n",
    "    tr = st[0].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The seismic data is downloaded from the IRIS/Earthscope Database using ObsPy. The data downloads as a trace, an array of data with attached metadata, which is then packaged into a stream, which can contain multiple traces. The daily seismic data records are then saved as [mseed files](https://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/), which preserve this data+metadata structure, but requires ObsPy or other specialized software to open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\n",
      "mkdir: cannot create directory ‘data/raw’: File exists\n",
      "Downloading data from 2024-08-15T00:00:00.000000Z to 2024-10-14T00:00:00.000000Z\n",
      "Data for day 20240815 already exists, skipping\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 43\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;66;03m# actually downloading\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m         st \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_waveforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mstation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mlocation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mchannel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mstarttime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarttime\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mendtime\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstarttime\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mbuffer\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mtr_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;66;03m# instrument sampling rate (hz)\u001b[39;00m\n\u001b[1;32m     51\u001b[0m         freq \u001b[38;5;241m=\u001b[39m st[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mstats\u001b[38;5;241m.\u001b[39msampling_rate\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/site-packages/obspy/clients/fdsn/client.py:872\u001b[0m, in \u001b[0;36mClient.get_waveforms\u001b[0;34m(self, network, station, location, channel, starttime, endtime, quality, minimumlength, longestonly, filename, attach_response, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_url_from_parameters(\n\u001b[1;32m    868\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataselect\u001b[39m\u001b[38;5;124m\"\u001b[39m, DEFAULT_PARAMETERS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataselect\u001b[39m\u001b[38;5;124m'\u001b[39m], kwargs)\n\u001b[1;32m    870\u001b[0m \u001b[38;5;66;03m# Gzip not worth it for MiniSEED and most likely disabled for this\u001b[39;00m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;66;03m# route in any case.\u001b[39;00m\n\u001b[0;32m--> 872\u001b[0m data_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gzip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    873\u001b[0m data_stream\u001b[38;5;241m.\u001b[39mseek(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/site-packages/obspy/clients/fdsn/client.py:1482\u001b[0m, in \u001b[0;36mClient._download\u001b[0;34m(self, url, return_string, data, use_gzip, content_type)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m content_type:\n\u001b[1;32m   1481\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m content_type\n\u001b[0;32m-> 1482\u001b[0m code, data \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopener\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_url_opener\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_gzip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_gzip\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m raise_on_error(code, data)\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/site-packages/obspy/clients/fdsn/client.py:1970\u001b[0m, in \u001b[0;36mdownload_url\u001b[0;34m(url, opener, timeout, headers, debug, return_string, data, use_gzip)\u001b[0m\n\u001b[1;32m   1967\u001b[0m     f \u001b[38;5;241m=\u001b[39m url_obj\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_string \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m-> 1970\u001b[0m     data \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mBytesIO(\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1972\u001b[0m     data \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/http/client.py:467\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunked:\n\u001b[0;32m--> 467\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_chunked\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    471\u001b[0m         \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/http/client.py:599\u001b[0m, in \u001b[0;36mHTTPResponse._read_chunked\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_left \u001b[38;5;241m=\u001b[39m chunk_left \u001b[38;5;241m-\u001b[39m amt\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 599\u001b[0m value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_safe_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_left\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    601\u001b[0m     amt \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m chunk_left\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/http/client.py:638\u001b[0m, in \u001b[0;36mHTTPResponse._safe_read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_read\u001b[39m(\u001b[38;5;28mself\u001b[39m, amt):\n\u001b[1;32m    632\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Read the number of bytes requested.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \n\u001b[1;32m    634\u001b[0m \u001b[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001b[39;00m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001b[39;00m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mread(amt)\n\u001b[1;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m<\u001b[39m amt:\n\u001b[1;32m    640\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m IncompleteRead(data, amt\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n",
      "File \u001b[0;32m~/anaconda3/envs/mlgeo/lib/python3.11/socket.py:718\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 718\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    720\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client = Client('IRIS')\n",
    "\n",
    "#creating variables to download data\n",
    "starttime = utc('2024-08-15T00:00:00')\n",
    "endtime = starttime + 60 * (60*60*24)\n",
    "day_range = 60\n",
    "\n",
    "#also add a buffer to both ends to chop off once the data has been filtered\n",
    "#and downsampled, kind of arbitrary length, 5% of a day (default ObsPy taper length)\n",
    "buffer = 60*60*24*0.05 #seconds\n",
    "\n",
    "net = 'HV'\n",
    "sta = 'UWB'\n",
    "loc = '*' #wildcard, generally don't care about location code\n",
    "cha = 'HHE' #horizontal component, as used in Zali et al\n",
    "\n",
    "#create folder for numpy streams to go into and initialize filepath\n",
    "!mkdir data\n",
    "!mkdir data/raw\n",
    "filepath = os.getcwd() + '/data/raw/'\n",
    "\n",
    "#create arrays to save dates\n",
    "dates = np.array([])\n",
    "\n",
    "print(f'Downloading data from {starttime} to {endtime}')\n",
    "\n",
    "#download the data piecemeal, here by day\n",
    "for day in range(day_range):\n",
    "    \n",
    "    tr_length = 24*60*60\n",
    "    \n",
    "    # Format the current date as YYYYMMDD for the filename\n",
    "    date_str = starttime.strftime('%Y%m%d')\n",
    "    filename = f\"{day + 1}_{date_str}_{net}{sta}.mseed\"\n",
    "    \n",
    "    # if file already exists, then skip\n",
    "    if os.path.exists(filepath + filename,):\n",
    "        print(f'Data for day {date_str} already exists, skipping')\n",
    "        starttime += tr_length\n",
    "    else:\n",
    "        try:\n",
    "            # actually downloading\n",
    "            st = client.get_waveforms(network=net,\n",
    "                                    station=sta,\n",
    "                                    location=loc,\n",
    "                                    channel=cha,\n",
    "                                    starttime=starttime-buffer,\n",
    "                                    endtime=starttime+buffer+tr_length)\n",
    "\n",
    "            # instrument sampling rate (hz)\n",
    "            freq = st[0].stats.sampling_rate\n",
    "\n",
    "            # merge traces within stream, linearly interpolating any gaps\n",
    "            st.merge(fill_value='interpolate')\n",
    "\n",
    "            ## Save data as MSEED, standard for storing seismic data\n",
    "            st.write(filepath + filename, format='MSEED')\n",
    "\n",
    "            # adding date\n",
    "            dates = np.append(dates, starttime.date)\n",
    "\n",
    "            print(f'Downloaded day {day + 1}')\n",
    "        except Exception as e:\n",
    "            print(f'Error downloading data for day {day + 1}: {e}')\n",
    "        \n",
    "    starttime += tr_length\n",
    "\n",
    "#save dates list for future use\n",
    "np.save(filepath+'date_list.csv', dates)\n",
    "\n",
    "print(f'data download complete, saved to {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Data Modalities and Formats\n",
    "\n",
    "#### Data Modalities\n",
    "The dataset consists of seismic data collected from a single horizontal component (HHE) of the HV.UWB. The data is recorded continuously over a period of 60 days, capturing the seismic activity before, during, and after the volcanic eruption.\n",
    "\n",
    "#### Data Formats\n",
    "1. **MSEED (Mini-SEED) Files**:\n",
    "    - The seismic data is stored in Mini-SEED format, which is a compact binary format used for storing time series data. Each file contains a day's worth of seismic data, including metadata such as the sampling rate and station information.\n",
    "    - Example file name: `1_YYYYMMDD_hvuwb.mseed`, `2_YYYYMMDD_hwuwb.mseed`, ..., `60_YYYYMMDD_hvuwb.mseed`.\n",
    "2. **Numpy Arrays**:\n",
    "    - The dates corresponding to each day's seismic data are stored in a numpy array and saved as a CSV file (`date_list.csv`). This array helps in mapping the MSEED files to their respective dates.\n",
    "    - Example: `dates = np.array([datetime.date(2021, 5, 16), datetime.date(2021, 5, 17), ...])`.\n",
    "\n",
    "#### Data Processing\n",
    "- The raw seismic data is downloaded using the ObsPy library from the IRIS/Earthscope Database.\n",
    "- The data is merged and interpolated to fill any gaps, ensuring a continuous time series.\n",
    "- The processed data is saved in the MSEED format, preserving both the time series and metadata.\n",
    "\n",
    "This structured approach ensures that the seismic data is well-organized and easily accessible for further analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Trace(s) in Stream:\n",
      "HV.UWB..HHE | 2024-10-09T22:48:00.000000Z - 2024-10-11T01:12:00.000000Z | 100.0 Hz, 9504001 samples\n"
     ]
    }
   ],
   "source": [
    "from obspy import read\n",
    "import glob\n",
    "\n",
    "# Folder containing mseed files\n",
    "#folder_path = '/path/to/your/folder'\n",
    "\n",
    "filepath = os.getcwd() + '/data/raw/'\n",
    "\n",
    "# Get the first mseed file in the folder\n",
    "first_file = glob.glob(f\"{filepath}/*.mseed\")[0]\n",
    "\n",
    "# Read and display the file\n",
    "st = read(first_file)\n",
    "print(st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
