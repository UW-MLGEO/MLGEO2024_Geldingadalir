{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Data Download Notebook\n",
    "\n",
    "Zali et al. 2024 pulls horizontal seismic data from a single horizontal component from a single station, demeaned and detrended but not converted from instrument response. The data is pulled from March 12 to June 24, ~104 days, beginning 7 days before the Geldingadalir eruption began. The data is also downsampled to the minimum sampling rate necessary to observe the local volcanic tremor.\n",
    "\n",
    "*Important Note:* This notebook runs using a different environment than this project's computational notebook. ObsPy is required, along with numpy and matplotlib\n",
    "\n",
    "This notebook downloads 60 days of data, beginning 08/15/2024, from the HV.UWB sensor at the of the Hawaiian Volcano Observatory's network, located on the island of Hawaii.\n",
    "\n",
    "> Magma intruded beneath the ground near Makaopuhi Crater—a well-known magma storage region on Kīlauea’s middle East Rift Zone on September 14. HVO published a Status Report alerting the public and partners to the activity, which was accompanied by hundreds of earthquakes and ground deformation. \n",
    "\n",
    "https://www.usgs.gov/observatories/hvo/science/eruption-kilauea-middle-east-rift-zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import obspy\n",
    "from obspy import UTCDateTime as utc\n",
    "from obspy.clients.fdsn import Client\n",
    "\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description\n",
    "\n",
    "The seismic data is downloaded from the IRIS/Earthscope Database using ObsPy. The data downloads as a trace, an array of data with attached metadata, which is then packaged into a stream, which can contain multiple traces. The daily seismic data records are then saved as [mseed files](https://ds.iris.edu/ds/nodes/dmc/data/formats/miniseed/), which preserve this data+metadata structure, but requires ObsPy or other specialized software to open."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set all of your variables for the station:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client('IRIS')\n",
    "\n",
    "#creating variables to download data\n",
    "starttime = utc('2024-08-15T00:00:00')\n",
    "endtime = starttime + 60 * (60*60*24)\n",
    "day_range = 60\n",
    "\n",
    "#also add a buffer to both ends to chop off once the data has been filtered\n",
    "#and downsampled, kind of arbitrary length, 5% of a day (default ObsPy taper length)\n",
    "buffer = 60*60*24*0.05 #seconds\n",
    "\n",
    "net = 'HV'\n",
    "sta = 'UWB'\n",
    "loc = '*' #wildcard, generally don't care about location code\n",
    "cha = 'HHE' #horizontal component, as used in Zali et al\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folder for numpy streams to go into and initialize filepath\n",
    "!mkdir data\n",
    "!mkdir data/raw\n",
    "filepath = os.getcwd() + '/data/raw/'\n",
    "\n",
    "#create arrays to save dates\n",
    "dates = np.array([])\n",
    "\n",
    "print(f'Downloading data from {starttime} to {endtime}')\n",
    "\n",
    "#download the data piecemeal, here by day\n",
    "for day in range(day_range):\n",
    "    \n",
    "    tr_length = 24*60*60\n",
    "    \n",
    "    # Format the current date as YYYYMMDD for the filename\n",
    "    date_str = starttime.strftime('%Y%m%d')\n",
    "    filename = f\"{day + 1}_{date_str}_{net}{sta}.mseed\"\n",
    "    \n",
    "    # if file already exists, then skip\n",
    "    if os.path.exists(filepath + filename,):\n",
    "        print(f'Data for day {date_str} already exists, skipping')\n",
    "        starttime += tr_length\n",
    "    else:\n",
    "        try:\n",
    "            # actually downloading\n",
    "            st = client.get_waveforms(network=net,\n",
    "                                    station=sta,\n",
    "                                    location=loc,\n",
    "                                    channel=cha,\n",
    "                                    starttime=starttime-buffer,\n",
    "                                    endtime=starttime+buffer+tr_length)\n",
    "\n",
    "            # instrument sampling rate (hz)\n",
    "            freq = st[0].stats.sampling_rate\n",
    "\n",
    "            # merge traces within stream, linearly interpolating any gaps\n",
    "            st.merge(fill_value='interpolate')\n",
    "\n",
    "            ## Save data as MSEED, standard for storing seismic data\n",
    "            st.write(filepath + filename, format='MSEED')\n",
    "\n",
    "            # adding date\n",
    "            dates = np.append(dates, starttime.date)\n",
    "\n",
    "            print(f'Downloaded day {day + 1}')\n",
    "        except Exception as e:\n",
    "            print(f'Error downloading data for day {day + 1}: {e}')\n",
    "        \n",
    "    starttime += tr_length\n",
    "\n",
    "#save dates list for future use\n",
    "np.save(filepath+'date_list.csv', dates)\n",
    "\n",
    "print(f'data download complete, saved to {filepath}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### Data Modalities and Formats\n",
    "\n",
    "#### Data Modalities\n",
    "The dataset consists of seismic data collected from a single horizontal component (HHE) of the HV.UWB. The data is recorded continuously over a period of 60 days, capturing the seismic activity before, during, and after the volcanic eruption.\n",
    "\n",
    "#### Data Formats\n",
    "1. **MSEED (Mini-SEED) Files**:\n",
    "    - The seismic data is stored in Mini-SEED format, which is a compact binary format used for storing time series data. Each file contains a day's worth of seismic data, including metadata such as the sampling rate and station information.\n",
    "    - Example file name: `1_YYYYMMDD_hvuwb.mseed`, `2_YYYYMMDD_hwuwb.mseed`, ..., `60_YYYYMMDD_hvuwb.mseed`.\n",
    "2. **Numpy Arrays**:\n",
    "    - The dates corresponding to each day's seismic data are stored in a numpy array and saved as a CSV file (`date_list.csv`). This array helps in mapping the MSEED files to their respective dates.\n",
    "    - Example: `dates = np.array([datetime.date(2021, 5, 16), datetime.date(2021, 5, 17), ...])`.\n",
    "\n",
    "#### Data Processing\n",
    "- The raw seismic data is downloaded using the ObsPy library from the IRIS/Earthscope Database.\n",
    "- The data is merged and interpolated to fill any gaps, ensuring a continuous time series.\n",
    "- The processed data is saved in the MSEED format, preserving both the time series and metadata.\n",
    "\n",
    "This structured approach ensures that the seismic data is well-organized and easily accessible for further analysis and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Trace(s) in Stream:\n",
      "HV.UWB..HHE | 2024-10-09T22:48:00.000000Z - 2024-10-11T01:12:00.000000Z | 100.0 Hz, 9504001 samples\n"
     ]
    }
   ],
   "source": [
    "from obspy import read\n",
    "import glob\n",
    "\n",
    "# Folder containing mseed files\n",
    "#folder_path = '/path/to/your/folder'\n",
    "\n",
    "filepath = os.getcwd() + '/data/raw/'\n",
    "\n",
    "# Get the first mseed file in the folder\n",
    "first_file = glob.glob(f\"{filepath}/*.mseed\")[0]\n",
    "\n",
    "# Read and display the file\n",
    "st = read(first_file)\n",
    "print(st)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
