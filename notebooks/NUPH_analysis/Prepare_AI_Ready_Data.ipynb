{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data for the model used in the paper ##\n",
    "\n",
    "Read each file and segment them into one hour windows. Each file will contain 28,800 samples per hour at an 8 Hz sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from obspy import read\n",
    "import glob\n",
    "import numpy as np\n",
    "from obspy import UTCDateTime\n",
    "\n",
    "# Define the processed and output folder paths\n",
    "processed_folder = os.getcwd() + '/data/processed'\n",
    "segmented_output_folder = os.getcwd() + '/data/segmented'\n",
    "os.makedirs(segmented_output_folder, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Define the target segment duration (1 hour) in seconds\n",
    "segment_duration = 3600  # seconds\n",
    "\n",
    "# Process each processed file for segmentation\n",
    "for file_path in glob.glob(f\"{processed_folder}/*.mseed\"):\n",
    "    # Read the processed file\n",
    "    st = read(file_path)\n",
    "    \n",
    "    # Normalize the traces in the stream object\n",
    "    st.normalize()\n",
    "    \n",
    "    # Split each trace in the Stream object into one-hour segments\n",
    "    for tr in st:\n",
    "        start_time = tr.stats.starttime\n",
    "        end_time = tr.stats.endtime\n",
    "        segment_start = start_time\n",
    "\n",
    "        # Loop over each one-hour segment\n",
    "        while segment_start + segment_duration <= end_time:\n",
    "            # Define the end time for the current segment\n",
    "            segment_end = segment_start + segment_duration\n",
    "\n",
    "            # Slice the trace to create a one-hour segment\n",
    "            segment = tr.slice(starttime=segment_start, endtime=segment_end)\n",
    "            \n",
    "            # Format the filename for the segment\n",
    "            segment_filename = f\"{tr.stats.network}_{tr.stats.station}_{tr.stats.channel}_{segment_start.strftime('%Y%m%dT%H%M%S')}.mseed\"\n",
    "            segment_filepath = os.path.join(segmented_output_folder, segment_filename)\n",
    "\n",
    "            # Save the one-hour segment as a new file\n",
    "            segment.write(segment_filepath, format=\"MSEED\")\n",
    "            print(f'Saved segment file: {segment_filepath}')\n",
    "\n",
    "            # Move to the next hour\n",
    "            segment_start = segment_end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the Fourier Transform with the `specified window_length` and `hop_length parameters` to produce a spectrogram of size (96, 128) for each one-hour segment. The data is saved in `segmented_output_folder` from the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Processed file: 9F_NUPH_HHE_20210505T234800.npy'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
=======
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from obspy import read\n",
    "import librosa\n",
    "from scipy.signal import resample\n",
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Define directories\n",
    "input_folder = os.getcwd() + '/data/raw'\n",
    "processed_folder = os.getcwd() + '/data/processed'\n",
    "segmented_output_folder = os.getcwd() + '/data/segmented'\n",
    "os.makedirs(segmented_output_folder, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "\n",
    "# Define constants\n",
    "target_sampling_rate = 8  # Hz\n",
    "segment_duration = 3600  # 1 hour in seconds\n",
    "window_length = 256\n",
    "hop_length = 224\n",
    "target_shape = (96, 128)\n",
    "\n",
    "# Initialize an empty list to store spectrograms\n",
    "spectrogram_list = []\n",
    "\n",
    "# Step 1: Process each file in the input folder\n",
    "for file_path in glob.glob(f\"{input_folder}/*.mseed\"):\n",
    "    # Read the file\n",
    "    st = read(file_path)\n",
    "    \n",
    "    # Process each trace\n",
    "    for tr in st:\n",
    "        # Resample the data to 8 Hz (assuming original sampling rate was 100 Hz)\n",
    "        tr.resample(target_sampling_rate)\n",
    "        \n",
    "        # Split into one-hour segments (28,800 samples each)\n",
    "        start_time = tr.stats.starttime\n",
    "        end_time = tr.stats.endtime\n",
    "        segment_start = start_time\n",
    "\n",
    "        while segment_start + segment_duration <= end_time:\n",
    "            # Define the end time for the current segment\n",
    "            segment_end = segment_start + segment_duration\n",
    "\n",
    "            # Slice the trace to create a one-hour segment\n",
    "            segment = tr.slice(starttime=segment_start, endtime=segment_end)\n",
    "            \n",
    "            # Compute STFT for the segment\n",
    "            signal = segment.data\n",
    "            stft_result = librosa.stft(signal, n_fft=window_length, hop_length=hop_length, win_length=window_length)\n",
    "            spectrogram = np.abs(stft_result) ** 2\n",
    "\n",
    "            # Resize spectrogram to target shape\n",
    "            spectrogram_resized = librosa.util.fix_length(spectrogram, size=target_shape[1], axis=1)[:target_shape[0], :]\n",
    "\n",
    "            # Log transformation for normalization\n",
    "            spectrogram_log = np.log1p(spectrogram_resized)\n",
    "\n",
    "            # Save the spectrogram (you could save the result as needed)\n",
    "            segment_filename = f\"{tr.stats.network}_{tr.stats.station}_{tr.stats.channel}_{segment_start.strftime('%Y%m%dT%H%M%S')}.npy\"\n",
    "            segment_filepath = os.path.join(segmented_output_folder, segment_filename)\n",
    "            np.save(segment_filepath, spectrogram_log)\n",
    "            #print(f'Saved spectrogram for segment: {segment_filepath}')\n",
    "\n",
    "            # Append the spectrogram to the list\n",
    "            spectrogram_list.append(spectrogram_log)\n",
    "\n",
    "            # Move to the next hour\n",
    "            segment_start = segment_end\n",
    "            \n",
    "            # display file being processed\n",
    "            time.sleep(0.1)\n",
    "            clear_output(wait=True)\n",
    "            display(f'Processing file: {segment_filename}')\n",
    "\n",
    "# Stack all spectrograms into a single numpy array and add batch and channel dimensions\n",
    "all_spectrograms = np.stack(spectrogram_list)\n",
    "all_spectrograms = all_spectrograms[:, np.newaxis, :, :]  # Shape: (batch_size, 1, 96, 128)\n",
    "print(f\"Shape of combined spectrogram array with batch and channel dimensions: {all_spectrograms.shape}\")\n",
    "\n",
    "# remove the single feature dimension (1)\n",
    "all_spectrograms = np.squeeze(all_spectrograms)\n",
    "\n",
    "# NOTE: FILE NAME IS HARD CODED HERE\n",
    "# Save the combined spectrogram array to Input.npy\n",
    "final_output_folder = os.getcwd()\n",
    "input_filepath = os.path.join(final_output_folder, \"Input_nuph.npy\")\n",
    "#input_filepath = os.path.join(final_output_folder + 'NUPH_analysis', \"Input_nuph.npy\")\n",
    "np.save(input_filepath, all_spectrograms)\n",
    "\n",
<<<<<<< Updated upstream
    "temp_filename = input_filepath.split('/')[-1]\n",
    "\n",
    "print(f'Saved combined spectrogram file: {temp_filename}')"
=======
    "print(f\"Saved combined spectrogram file: {input_filepath.split('/')[-1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure there are spectrograms to plot\n",
    "if all_spectrograms.size > 0:\n",
    "    for i in range(10):\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(all_spectrograms[i].flatten())\n",
    "        plt.title(f'Spectrogram {i} as Line Plot')\n",
    "        plt.xlabel('Frequency Bins')\n",
    "        plt.ylabel('Log Power')\n",
    "        plt.show()\n",
    "    # Plot the first spectrogram\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.imshow(all_spectrograms[0], aspect='auto', origin='lower', cmap='viridis')\n",
    "    # plt.colorbar(label='Log Power')\n",
    "    # plt.title('First Spectrogram in all_spectrograms')\n",
    "    # plt.xlabel('Time Bins')\n",
    "    # plt.ylabel('Frequency Bins')\n",
    "    # plt.show()\n",
    "else:\n",
    "    print(\"No spectrograms found in all_spectrograms.\")"
>>>>>>> Stashed changes
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< Updated upstream
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of combined spectrogram array with batch and channel dimensions: (2542, 96, 128)\n",
      "Number of files processed: 2542\n",
      "Shape of combined spectrogram array Input.npy: (2542, 96, 128)\n",
      "Number of files processed: 2542\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
=======
   "outputs": [],
   "source": [
    "# display some of the data in Input.npy\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(data_file[i])\n",
    "    plt.title('Seismic data from station NUPH ' + str(i))\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Amplitude')\n",
    "    # Assuming 'y' contains the labels for the data\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "# show the top 10 rows\n",
    "#print(data_file[:3])\n",
    "\n",
    "# display number of dimensions of data_file\n",
    "print(f'Number of dimensions:', data_file.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display information on Input.npy\n",
    "print(f\"Shape of combined spectrogram array with batch and channel dimensions: {all_spectrograms.shape}\")\n",
    "print(f\"Number of files processed: {all_spectrograms.shape[0]}\")\n",
    "\n",
    "# load Input.npy and display information for confirmation\n",
    "input_data_file_t = np.load(input_filepath)\n",
    "print(f\"Shape of combined spectrogram array Input.npy: {input_data_file_t.shape}\")\n",
    "print(f\"Number of files processed: {input_data_file_t.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> Stashed changes
   "source": [
    "#display information on Input.npy\n",
    "print(f\"Shape of combined spectrogram array with batch and channel dimensions: {all_spectrograms.shape}\")\n",
    "print(f\"Number of files processed: {all_spectrograms.shape[0]}\")\n",
    "\n",
    "# load Input.npy and display information for confirmation\n",
    "input_data_file_t = np.load(input_filepath)\n",
    "print(f\"Shape of combined spectrogram array Input.npy: {input_data_file_t.shape}\")\n",
    "print(f\"Number of files processed: {input_data_file_t.shape[0]}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Input shape is [all_spectrograms.shape[0], 1, 96, 128] where:\n",
    "\n",
    "all_spectrograms.shape[0]: batch size -> the number of hours of data processed\n",
    "1: input channel. Probably indicates there is only one feature per time step\n",
    "96: height (or time)\n",
    "128: width (or frequency)  \n",
    "\n",
    "11/14/24 - input channel removed\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
